{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:50:28.721976Z",
     "start_time": "2020-03-06T20:50:28.714979Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, GlobalMaxPool1D\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:54:52.922602Z",
     "start_time": "2020-03-06T20:54:52.842412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2491.0</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2491.0</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>551</td>\n",
       "      <td>86</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2489.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>120</td>\n",
       "      <td>86</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2488.0</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>120</td>\n",
       "      <td>86</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2484.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>120</td>\n",
       "      <td>85</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85060</th>\n",
       "      <td>2235.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>115</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85061</th>\n",
       "      <td>2234.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>115</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85062</th>\n",
       "      <td>2234.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>115</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85063</th>\n",
       "      <td>2233.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>114</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85064</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>115</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85065 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_pos   y_pos  channel_1  channel_2  channel_3  channel_4\n",
       "0      2491.0  1219.0          0          0          0          0\n",
       "1      2491.0  1219.0        551         86         24         14\n",
       "2      2489.0  1217.0        120         86         24         19\n",
       "3      2488.0  1216.0        120         86         24         25\n",
       "4      2484.0  1214.0        120         85         24         26\n",
       "...       ...     ...        ...        ...        ...        ...\n",
       "85060  2235.0   643.0        115         60         18         35\n",
       "85061  2234.0   643.0        115         60         18         36\n",
       "85062  2234.0   643.0        115         60         17         36\n",
       "85063  2233.0   642.0        114         60         17         35\n",
       "85064  2232.0   642.0        115         60         17         35\n",
       "\n",
       "[85065 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw_recording.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:54:54.018984Z",
     "start_time": "2020-03-06T20:54:54.013977Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.drop(columns=['time', 'start', 'end'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:55:23.506715Z",
     "start_time": "2020-03-06T20:54:54.824576Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(1,500):\n",
    "\n",
    "    df[f'channel_1_{i}'] = df['channel_1'].shift(i)\n",
    "    df[f'channel_2_{i}'] = df['channel_2'].shift(i)\n",
    "    df[f'channel_3_{i}'] = df['channel_3'].shift(i)\n",
    "    df[f'channel_4_{i}'] = df['channel_4'].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:55:23.521705Z",
     "start_time": "2020-03-06T20:55:23.509701Z"
    }
   },
   "outputs": [],
   "source": [
    "df['x_diff'] = df['x_pos'].diff()\n",
    "df['y_diff'] = df['y_pos'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:55:28.490354Z",
     "start_time": "2020-03-06T20:55:23.527710Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:50:58.713457Z",
     "start_time": "2020-03-06T20:50:57.734335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_4</th>\n",
       "      <th>channel_1_1</th>\n",
       "      <th>channel_2_1</th>\n",
       "      <th>channel_3_1</th>\n",
       "      <th>channel_4_1</th>\n",
       "      <th>...</th>\n",
       "      <th>channel_1_498</th>\n",
       "      <th>channel_2_498</th>\n",
       "      <th>channel_3_498</th>\n",
       "      <th>channel_4_498</th>\n",
       "      <th>channel_1_499</th>\n",
       "      <th>channel_2_499</th>\n",
       "      <th>channel_3_499</th>\n",
       "      <th>channel_4_499</th>\n",
       "      <th>x_diff</th>\n",
       "      <th>y_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1740.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>111</td>\n",
       "      <td>302</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>111.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>551.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1736.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>111</td>\n",
       "      <td>302</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>111.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1731.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>110</td>\n",
       "      <td>301</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>111.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1731.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>111</td>\n",
       "      <td>301</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>110.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1728.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>110</td>\n",
       "      <td>300</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>111.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    x_pos   y_pos  channel_1  channel_2  channel_3  channel_4  channel_1_1  \\\n",
       "0  1740.0  1038.0        111        302         39         16        111.0   \n",
       "1  1736.0  1038.0        111        302         39         16        111.0   \n",
       "2  1731.0  1037.0        110        301         39         16        111.0   \n",
       "3  1731.0  1037.0        111        301         39         16        110.0   \n",
       "4  1728.0  1036.0        110        300         39         16        111.0   \n",
       "\n",
       "   channel_2_1  channel_3_1  channel_4_1  ...  channel_1_498  channel_2_498  \\\n",
       "0        302.0         39.0         16.0  ...          551.0           86.0   \n",
       "1        302.0         39.0         16.0  ...          120.0           86.0   \n",
       "2        302.0         39.0         16.0  ...          120.0           86.0   \n",
       "3        301.0         39.0         16.0  ...          120.0           85.0   \n",
       "4        301.0         39.0         16.0  ...          120.0           86.0   \n",
       "\n",
       "   channel_3_498  channel_4_498  channel_1_499  channel_2_499  channel_3_499  \\\n",
       "0           24.0           14.0            0.0            0.0            0.0   \n",
       "1           24.0           19.0          551.0           86.0           24.0   \n",
       "2           24.0           25.0          120.0           86.0           24.0   \n",
       "3           24.0           26.0          120.0           86.0           24.0   \n",
       "4           24.0           26.0          120.0           85.0           24.0   \n",
       "\n",
       "   channel_4_499  x_diff  y_diff  \n",
       "0            0.0     0.0     0.0  \n",
       "1           14.0    -4.0     0.0  \n",
       "2           19.0    -5.0    -1.0  \n",
       "3           25.0     0.0     0.0  \n",
       "4           26.0    -3.0    -1.0  \n",
       "\n",
       "[5 rows x 2004 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:51:40.241959Z",
     "start_time": "2020-03-06T20:51:39.487693Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = df[df['x_diff'] != 0]\n",
    "# df = df[df['y_diff'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:46:50.996050Z",
     "start_time": "2020-03-06T20:46:50.968041Z"
    }
   },
   "outputs": [],
   "source": [
    "# print((df['x_diff'].value_counts()[0], sum(df['x_diff'].value_counts().reset_index(drop = True)[1:])))\n",
    "# df['y_diff'].value_counts()[0], sum(df['y_diff'].value_counts().reset_index(drop = True)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:46:43.526400Z",
     "start_time": "2020-03-06T20:46:29.583356Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.concat([df, df[df['x_diff'] != 0].sample(52201 - 32365, replace = True)], axis=0)\n",
    "# df = pd.concat([df, df[df['y_diff'] != 0].sample(52201 - 32365, replace = True)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:55:31.281527Z",
     "start_time": "2020-03-06T20:55:28.492312Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['x_pos', 'y_pos', 'x_diff', 'y_diff'])\n",
    "y = np.array(df['x_diff'])\n",
    "\n",
    "W = X.copy()\n",
    "z = np.array(df['y_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T16:06:37.483421Z",
     "start_time": "2020-03-06T16:06:37.477393Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:55:37.755754Z",
     "start_time": "2020-03-06T20:55:31.283486Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "W_train, W_test, z_train, z_test = train_test_split(W, z, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:52:05.435362Z",
     "start_time": "2020-03-06T20:52:05.289207Z"
    }
   },
   "outputs": [],
   "source": [
    "model_x = Sequential()\n",
    "\n",
    "\n",
    "# model_x.add(Conv1D(512, kernel_size=5, input_shape = (2000,1), activation='relu'))\n",
    "# model_x.add(GlobalMaxPool1D())\n",
    "\n",
    "model_x.add(Dense(128, activation='relu', input_shape = (2000,)))\n",
    "model_x.add(Dense(32, activation = 'relu'))\n",
    "model_x.add(Dense(1, activation=tf.keras.activations.linear))\n",
    "\n",
    "model_x.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:52:56.489024Z",
     "start_time": "2020-03-06T20:52:06.455940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63424 samples, validate on 21142 samples\n",
      "Epoch 1/20\n",
      "63424/63424 [==============================] - 3s 44us/sample - loss: 799.2383 - acc: 0.5691 - val_loss: 13.0713 - val_acc: 0.6129\n",
      "Epoch 2/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 16.9772 - acc: 0.6165 - val_loss: 11.9552 - val_acc: 0.6142\n",
      "Epoch 3/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18.7157 - acc: 0.6173 - val_loss: 11.8995 - val_acc: 0.6141\n",
      "Epoch 4/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.4728 - acc: 0.6182 - val_loss: 11.8670 - val_acc: 0.6144\n",
      "Epoch 5/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3097 - acc: 0.6182 - val_loss: 11.8675 - val_acc: 0.6144\n",
      "Epoch 6/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3097 - acc: 0.6182 - val_loss: 11.8665 - val_acc: 0.6144\n",
      "Epoch 7/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3099 - acc: 0.6182 - val_loss: 11.8665 - val_acc: 0.6144\n",
      "Epoch 8/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3098 - acc: 0.6182 - val_loss: 11.8664 - val_acc: 0.6144\n",
      "Epoch 9/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3096 - acc: 0.6182 - val_loss: 11.8675 - val_acc: 0.6144\n",
      "Epoch 10/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3097 - acc: 0.6182 - val_loss: 11.8670 - val_acc: 0.6144\n",
      "Epoch 11/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3099 - acc: 0.6182 - val_loss: 11.8665 - val_acc: 0.6144\n",
      "Epoch 12/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3098 - acc: 0.6182 - val_loss: 11.8669 - val_acc: 0.6144\n",
      "Epoch 13/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3098 - acc: 0.6182 - val_loss: 11.8664 - val_acc: 0.6144\n",
      "Epoch 14/20\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 12.3098 - acc: 0.6182 - val_loss: 11.8665 - val_acc: 0.6144\n",
      "Epoch 15/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3099 - acc: 0.6182 - val_loss: 11.8664 - val_acc: 0.6144\n",
      "Epoch 16/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3099 - acc: 0.6182 - val_loss: 11.8665 - val_acc: 0.6144\n",
      "Epoch 17/20\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 12.3098 - acc: 0.6182 - val_loss: 11.8664 - val_acc: 0.6144\n",
      "Epoch 18/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3099 - acc: 0.6182 - val_loss: 11.8666 - val_acc: 0.6144\n",
      "Epoch 19/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3099 - acc: 0.6182 - val_loss: 11.8668 - val_acc: 0.6144\n",
      "Epoch 20/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 12.3099 - acc: 0.6182 - val_loss: 11.8665 - val_acc: 0.6144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efb1c740860>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_x.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:53:03.688416Z",
     "start_time": "2020-03-06T20:53:03.550348Z"
    }
   },
   "outputs": [],
   "source": [
    "model_y = Sequential()\n",
    "\n",
    "model_y.add(Dense(128, input_shape = (2000,), activation='relu'))\n",
    "model_y.add(Dense(32, activation = 'relu'))\n",
    "model_y.add(Dense(1, activation=tf.keras.activations.linear))\n",
    "\n",
    "model_y.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:53:34.869603Z",
     "start_time": "2020-03-06T20:53:04.247457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63424 samples, validate on 21142 samples\n",
      "Epoch 1/20\n",
      "63424/63424 [==============================] - 3s 45us/sample - loss: 283.0481 - acc: 0.6051 - val_loss: 6.3085 - val_acc: 0.6453\n",
      "Epoch 2/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 39.9871 - acc: 0.6431 - val_loss: 5.9073 - val_acc: 0.6463\n",
      "Epoch 3/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 33.2127 - acc: 0.6457 - val_loss: 5.8216 - val_acc: 0.6470\n",
      "Epoch 4/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1755 - acc: 0.6462 - val_loss: 5.8213 - val_acc: 0.6470\n",
      "Epoch 5/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1754 - acc: 0.6462 - val_loss: 5.8220 - val_acc: 0.6470\n",
      "Epoch 6/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1754 - acc: 0.6462 - val_loss: 5.8207 - val_acc: 0.6470\n",
      "Epoch 7/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1755 - acc: 0.6462 - val_loss: 5.8205 - val_acc: 0.6470\n",
      "Epoch 8/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1755 - acc: 0.6462 - val_loss: 5.8210 - val_acc: 0.6470\n",
      "Epoch 9/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1757 - acc: 0.6462 - val_loss: 5.8209 - val_acc: 0.6470\n",
      "Epoch 10/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1755 - acc: 0.6462 - val_loss: 5.8205 - val_acc: 0.6470\n",
      "Epoch 11/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1758 - acc: 0.6462 - val_loss: 5.8209 - val_acc: 0.6470\n",
      "Epoch 12/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1757 - acc: 0.6462 - val_loss: 5.8208 - val_acc: 0.6470\n",
      "Epoch 13/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1756 - acc: 0.6462 - val_loss: 5.8207 - val_acc: 0.6470\n",
      "Epoch 14/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1755 - acc: 0.6462 - val_loss: 5.8211 - val_acc: 0.6470\n",
      "Epoch 15/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1757 - acc: 0.6462 - val_loss: 5.8210 - val_acc: 0.6470\n",
      "Epoch 16/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1752 - acc: 0.6462 - val_loss: 5.8205 - val_acc: 0.6470\n",
      "Epoch 17/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1757 - acc: 0.6462 - val_loss: 5.8208 - val_acc: 0.6470\n",
      "Epoch 18/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1754 - acc: 0.6462 - val_loss: 5.8206 - val_acc: 0.6470\n",
      "Epoch 19/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1757 - acc: 0.6462 - val_loss: 5.8205 - val_acc: 0.6470\n",
      "Epoch 20/20\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17.1756 - acc: 0.6462 - val_loss: 5.8212 - val_acc: 0.6470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efb1c07b5f8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_y.fit(W_train, z_train, validation_data = (W_test, z_test), epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:53:46.177661Z",
     "start_time": "2020-03-06T20:53:37.842541Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,100))\n",
    "plt.plot(y, z);\n",
    "plt.plot(model_x.predict(X), model_y.predict(W));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:53:52.932572Z",
     "start_time": "2020-03-06T20:53:46.177661Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,100))\n",
    "plt.plot(y);\n",
    "plt.plot(model_x.predict(X));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:53:59.452191Z",
     "start_time": "2020-03-06T20:53:52.936574Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,100))\n",
    "plt.plot(z);\n",
    "plt.plot(model_x.predict(W));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:50:00.158964Z",
     "start_time": "2020-03-06T20:47:14.667Z"
    }
   },
   "outputs": [],
   "source": [
    "model_x.save('../pickled_models/nn_x')\n",
    "model_y.save('../pickled_models/nn_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:13:05.312452Z",
     "start_time": "2020-03-06T20:13:03.594627Z"
    }
   },
   "outputs": [],
   "source": [
    "q = np.array(df[['x_pos', 'y_pos']])\n",
    "\n",
    "P_train, P_test, q_train, q_test = train_test_split(X, q, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:13:05.435126Z",
     "start_time": "2020-03-06T20:13:05.312452Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_shape = (2000,), activation='relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(2, activation=tf.keras.activations.linear))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:16:55.575598Z",
     "start_time": "2020-03-06T20:13:05.437088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63424 samples, validate on 21142 samples\n",
      "Epoch 1/1000\n",
      "63424/63424 [==============================] - 3s 45us/sample - loss: 513359.2366 - acc: 0.8877 - val_loss: 445607.9853 - val_acc: 0.8870\n",
      "Epoch 2/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 391354.2949 - acc: 0.8883 - val_loss: 383173.8352 - val_acc: 0.8849\n",
      "Epoch 3/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 329613.8986 - acc: 0.8887 - val_loss: 345535.4367 - val_acc: 0.8852\n",
      "Epoch 4/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 287580.7344 - acc: 0.8900 - val_loss: 316877.7422 - val_acc: 0.8855\n",
      "Epoch 5/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 258128.6092 - acc: 0.8914 - val_loss: 304781.6056 - val_acc: 0.8874\n",
      "Epoch 6/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 236578.8390 - acc: 0.8937 - val_loss: 284405.2699 - val_acc: 0.8885\n",
      "Epoch 7/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 215729.3826 - acc: 0.8966 - val_loss: 279518.4403 - val_acc: 0.8892\n",
      "Epoch 8/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 201549.4381 - acc: 0.8995 - val_loss: 265639.1143 - val_acc: 0.8973\n",
      "Epoch 9/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 188167.6217 - acc: 0.9023 - val_loss: 267396.6300 - val_acc: 0.8958\n",
      "Epoch 10/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 177605.3617 - acc: 0.9038 - val_loss: 279140.3763 - val_acc: 0.8923\n",
      "Epoch 11/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 167092.9001 - acc: 0.9057 - val_loss: 254702.3309 - val_acc: 0.8922\n",
      "Epoch 12/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 159945.1702 - acc: 0.9073 - val_loss: 253263.0274 - val_acc: 0.8958\n",
      "Epoch 13/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 152546.0875 - acc: 0.9084 - val_loss: 254759.7835 - val_acc: 0.8915\n",
      "Epoch 14/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 146066.8274 - acc: 0.9089 - val_loss: 258917.0296 - val_acc: 0.8958\n",
      "Epoch 15/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 140230.9806 - acc: 0.9097 - val_loss: 247457.4958 - val_acc: 0.8999\n",
      "Epoch 16/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 135303.6920 - acc: 0.9120 - val_loss: 263102.3656 - val_acc: 0.8942\n",
      "Epoch 17/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 129987.7026 - acc: 0.9124 - val_loss: 252134.4594 - val_acc: 0.8932\n",
      "Epoch 18/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 127091.0695 - acc: 0.9125 - val_loss: 250250.4439 - val_acc: 0.8939\n",
      "Epoch 19/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 121145.6160 - acc: 0.9132 - val_loss: 254073.9726 - val_acc: 0.8923\n",
      "Epoch 20/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 118299.6396 - acc: 0.9135 - val_loss: 244562.4178 - val_acc: 0.8972\n",
      "Epoch 21/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 115411.9761 - acc: 0.9144 - val_loss: 264332.9121 - val_acc: 0.8966\n",
      "Epoch 22/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 111847.2885 - acc: 0.9155 - val_loss: 294368.2342 - val_acc: 0.8932\n",
      "Epoch 23/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 108375.6643 - acc: 0.9156 - val_loss: 280753.8989 - val_acc: 0.8942\n",
      "Epoch 24/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 106180.7771 - acc: 0.9164 - val_loss: 274145.9281 - val_acc: 0.8951\n",
      "Epoch 25/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 103314.4786 - acc: 0.9179 - val_loss: 272117.3585 - val_acc: 0.8935\n",
      "Epoch 26/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 100910.8433 - acc: 0.9172 - val_loss: 267273.9488 - val_acc: 0.8927\n",
      "Epoch 27/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 98212.1308 - acc: 0.9190 - val_loss: 271951.1262 - val_acc: 0.8984\n",
      "Epoch 28/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 97200.5795 - acc: 0.9192 - val_loss: 286643.9511 - val_acc: 0.8990\n",
      "Epoch 29/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 93455.0964 - acc: 0.9200 - val_loss: 285209.6212 - val_acc: 0.9002\n",
      "Epoch 30/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 92473.6044 - acc: 0.9212 - val_loss: 277361.2237 - val_acc: 0.8987\n",
      "Epoch 31/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 90529.7134 - acc: 0.9208 - val_loss: 285604.4097 - val_acc: 0.9006\n",
      "Epoch 32/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 88667.6637 - acc: 0.9216 - val_loss: 300556.9909 - val_acc: 0.9015\n",
      "Epoch 33/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 87072.0959 - acc: 0.9230 - val_loss: 310154.3507 - val_acc: 0.8940\n",
      "Epoch 34/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 85910.7079 - acc: 0.9234 - val_loss: 320134.4773 - val_acc: 0.8949\n",
      "Epoch 35/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 84788.9766 - acc: 0.9235 - val_loss: 310766.5175 - val_acc: 0.9012\n",
      "Epoch 36/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 82124.0728 - acc: 0.9240 - val_loss: 360095.6063 - val_acc: 0.8992\n",
      "Epoch 37/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 81169.3477 - acc: 0.9253 - val_loss: 320660.1444 - val_acc: 0.8965\n",
      "Epoch 38/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 79203.0342 - acc: 0.9257 - val_loss: 296165.6324 - val_acc: 0.8975\n",
      "Epoch 39/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 78637.3111 - acc: 0.9261 - val_loss: 325366.3059 - val_acc: 0.9054\n",
      "Epoch 40/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 77113.6737 - acc: 0.9262 - val_loss: 301765.8462 - val_acc: 0.9003\n",
      "Epoch 41/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 75785.8183 - acc: 0.9277 - val_loss: 300559.4216 - val_acc: 0.9046\n",
      "Epoch 42/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 75383.0197 - acc: 0.9261 - val_loss: 302540.0528 - val_acc: 0.9022\n",
      "Epoch 43/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 74474.5752 - acc: 0.9275 - val_loss: 342351.8840 - val_acc: 0.9059\n",
      "Epoch 44/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 72402.6261 - acc: 0.9283 - val_loss: 325404.4187 - val_acc: 0.8976\n",
      "Epoch 45/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 72316.1860 - acc: 0.9290 - val_loss: 345891.1666 - val_acc: 0.9024\n",
      "Epoch 46/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 71074.6964 - acc: 0.9289 - val_loss: 320099.7030 - val_acc: 0.9011\n",
      "Epoch 47/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 70378.8840 - acc: 0.9289 - val_loss: 336826.0169 - val_acc: 0.9002\n",
      "Epoch 48/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 69402.6714 - acc: 0.9299 - val_loss: 337066.1568 - val_acc: 0.9065\n",
      "Epoch 49/1000\n",
      "63424/63424 [==============================] - 3s 43us/sample - loss: 68933.6933 - acc: 0.9302 - val_loss: 327248.0866 - val_acc: 0.9029\n",
      "Epoch 50/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 68236.2307 - acc: 0.9301 - val_loss: 342084.3477 - val_acc: 0.9065\n",
      "Epoch 51/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 67557.4530 - acc: 0.9302 - val_loss: 332325.5562 - val_acc: 0.9046\n",
      "Epoch 52/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 66635.8246 - acc: 0.9305 - val_loss: 335701.0954 - val_acc: 0.9055\n",
      "Epoch 53/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 65679.0400 - acc: 0.9307 - val_loss: 355255.1539 - val_acc: 0.8985\n",
      "Epoch 54/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 65254.6140 - acc: 0.9309 - val_loss: 338380.7152 - val_acc: 0.9004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 64127.3548 - acc: 0.9314 - val_loss: 352945.2734 - val_acc: 0.8985\n",
      "Epoch 56/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 64097.5780 - acc: 0.9308 - val_loss: 366121.4318 - val_acc: 0.9028\n",
      "Epoch 57/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 62088.4563 - acc: 0.9321 - val_loss: 354193.0124 - val_acc: 0.9026\n",
      "Epoch 58/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 63230.2791 - acc: 0.9314 - val_loss: 354715.6877 - val_acc: 0.9022\n",
      "Epoch 59/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 61661.4751 - acc: 0.9320 - val_loss: 337583.1079 - val_acc: 0.8966\n",
      "Epoch 60/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 61775.5633 - acc: 0.9324 - val_loss: 363520.0232 - val_acc: 0.8987\n",
      "Epoch 61/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 60755.1140 - acc: 0.9331 - val_loss: 368249.3070 - val_acc: 0.8986\n",
      "Epoch 62/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 60326.6292 - acc: 0.9330 - val_loss: 367912.2972 - val_acc: 0.9006\n",
      "Epoch 63/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 59841.3833 - acc: 0.9327 - val_loss: 348264.4160 - val_acc: 0.8989\n",
      "Epoch 64/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 59337.4704 - acc: 0.9335 - val_loss: 344407.6275 - val_acc: 0.8971\n",
      "Epoch 65/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 58922.8205 - acc: 0.9334 - val_loss: 375249.4151 - val_acc: 0.9059\n",
      "Epoch 66/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 58349.9953 - acc: 0.9334 - val_loss: 365107.9647 - val_acc: 0.9057\n",
      "Epoch 67/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 57879.0233 - acc: 0.9340 - val_loss: 366738.9383 - val_acc: 0.9055\n",
      "Epoch 68/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 57380.0620 - acc: 0.9346 - val_loss: 361171.1604 - val_acc: 0.9050\n",
      "Epoch 69/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 57555.1290 - acc: 0.9345 - val_loss: 339547.7525 - val_acc: 0.9041\n",
      "Epoch 70/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 56312.2358 - acc: 0.9344 - val_loss: 342767.0836 - val_acc: 0.8927\n",
      "Epoch 71/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 56480.3771 - acc: 0.9341 - val_loss: 369693.1420 - val_acc: 0.8989\n",
      "Epoch 72/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 56112.5507 - acc: 0.9347 - val_loss: 344457.1463 - val_acc: 0.8956\n",
      "Epoch 73/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 55558.2584 - acc: 0.9352 - val_loss: 374144.5815 - val_acc: 0.9069\n",
      "Epoch 74/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 54710.2772 - acc: 0.9360 - val_loss: 383469.4815 - val_acc: 0.9014\n",
      "Epoch 75/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 54918.4867 - acc: 0.9360 - val_loss: 348933.7855 - val_acc: 0.9025\n",
      "Epoch 76/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 54018.5851 - acc: 0.9351 - val_loss: 350587.7683 - val_acc: 0.9040\n",
      "Epoch 77/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 53804.2032 - acc: 0.9368 - val_loss: 374101.7900 - val_acc: 0.8977\n",
      "Epoch 78/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 53786.8091 - acc: 0.9362 - val_loss: 356771.9916 - val_acc: 0.9013\n",
      "Epoch 79/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 53002.7761 - acc: 0.9362 - val_loss: 348971.6837 - val_acc: 0.8977\n",
      "Epoch 80/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 52237.1473 - acc: 0.9366 - val_loss: 358802.0306 - val_acc: 0.9002\n",
      "Epoch 81/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 52301.1046 - acc: 0.9375 - val_loss: 367826.1617 - val_acc: 0.9014\n",
      "Epoch 82/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 52532.6891 - acc: 0.9366 - val_loss: 373457.5626 - val_acc: 0.9037\n",
      "Epoch 83/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 51897.9154 - acc: 0.9374 - val_loss: 338099.7674 - val_acc: 0.9023\n",
      "Epoch 84/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 50935.7051 - acc: 0.9380 - val_loss: 339522.0653 - val_acc: 0.9042\n",
      "Epoch 85/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 51700.0980 - acc: 0.9390 - val_loss: 334749.0899 - val_acc: 0.9103\n",
      "Epoch 86/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 51155.8086 - acc: 0.9376 - val_loss: 369753.2132 - val_acc: 0.9008\n",
      "Epoch 87/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 50887.2988 - acc: 0.9389 - val_loss: 359168.5843 - val_acc: 0.9030\n",
      "Epoch 88/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 49868.3999 - acc: 0.9391 - val_loss: 383489.1076 - val_acc: 0.9048\n",
      "Epoch 89/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 50144.8089 - acc: 0.9391 - val_loss: 334977.9123 - val_acc: 0.9025\n",
      "Epoch 90/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 50582.2940 - acc: 0.9392 - val_loss: 356204.9621 - val_acc: 0.9063\n",
      "Epoch 91/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 49433.5076 - acc: 0.9398 - val_loss: 346000.5611 - val_acc: 0.9034\n",
      "Epoch 92/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 49023.2496 - acc: 0.9394 - val_loss: 353695.1508 - val_acc: 0.9051\n",
      "Epoch 93/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 49604.6569 - acc: 0.9400 - val_loss: 360247.0299 - val_acc: 0.9053\n",
      "Epoch 94/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 48610.1096 - acc: 0.9399 - val_loss: 398523.6540 - val_acc: 0.9062\n",
      "Epoch 95/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 48821.6775 - acc: 0.9403 - val_loss: 352035.5937 - val_acc: 0.9104\n",
      "Epoch 96/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 48093.7265 - acc: 0.9410 - val_loss: 352688.0381 - val_acc: 0.9011\n",
      "Epoch 97/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 47977.3929 - acc: 0.9402 - val_loss: 345892.8686 - val_acc: 0.9016\n",
      "Epoch 98/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 47656.6112 - acc: 0.9409 - val_loss: 345339.3193 - val_acc: 0.9028\n",
      "Epoch 99/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 47966.5891 - acc: 0.9403 - val_loss: 345136.5404 - val_acc: 0.9045\n",
      "Epoch 100/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 47178.3930 - acc: 0.9406 - val_loss: 372458.8117 - val_acc: 0.9021\n",
      "Epoch 101/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 46687.5289 - acc: 0.9417 - val_loss: 376679.4495 - val_acc: 0.8973\n",
      "Epoch 102/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 47399.4335 - acc: 0.9410 - val_loss: 381471.6447 - val_acc: 0.9065\n",
      "Epoch 103/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 46399.5452 - acc: 0.9419 - val_loss: 362472.9644 - val_acc: 0.9003\n",
      "Epoch 104/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 46303.2976 - acc: 0.9408 - val_loss: 395610.2663 - val_acc: 0.9080\n",
      "Epoch 105/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 46324.4897 - acc: 0.9427 - val_loss: 362351.4577 - val_acc: 0.9072\n",
      "Epoch 106/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 45995.7576 - acc: 0.9414 - val_loss: 345931.7428 - val_acc: 0.9054\n",
      "Epoch 107/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 45470.3833 - acc: 0.9427 - val_loss: 344307.6939 - val_acc: 0.9051\n",
      "Epoch 108/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 45103.3961 - acc: 0.9428 - val_loss: 374245.2651 - val_acc: 0.9038\n",
      "Epoch 109/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 45404.4734 - acc: 0.9422 - val_loss: 387293.4840 - val_acc: 0.9029\n",
      "Epoch 110/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 45132.6865 - acc: 0.9428 - val_loss: 357721.1945 - val_acc: 0.9070\n",
      "Epoch 111/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 44425.2799 - acc: 0.9436 - val_loss: 380535.2776 - val_acc: 0.8969\n",
      "Epoch 112/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 44744.4389 - acc: 0.9428 - val_loss: 368201.3222 - val_acc: 0.9105\n",
      "Epoch 113/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 44114.9435 - acc: 0.9435 - val_loss: 348982.6910 - val_acc: 0.9084\n",
      "Epoch 114/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 44295.4586 - acc: 0.9426 - val_loss: 368968.3164 - val_acc: 0.9075\n",
      "Epoch 115/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 44072.2816 - acc: 0.9441 - val_loss: 357280.8651 - val_acc: 0.9092\n",
      "Epoch 116/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 44438.4619 - acc: 0.9441 - val_loss: 375503.8649 - val_acc: 0.8997\n",
      "Epoch 117/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 43722.3163 - acc: 0.9441 - val_loss: 357752.4001 - val_acc: 0.9099\n",
      "Epoch 118/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 43290.4694 - acc: 0.9437 - val_loss: 376822.2161 - val_acc: 0.9145\n",
      "Epoch 119/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 43169.0390 - acc: 0.9441 - val_loss: 364337.3823 - val_acc: 0.9064\n",
      "Epoch 120/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 43416.2714 - acc: 0.9439 - val_loss: 366949.0694 - val_acc: 0.9084\n",
      "Epoch 121/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 42808.3692 - acc: 0.9447 - val_loss: 328633.3251 - val_acc: 0.9034\n",
      "Epoch 122/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 42842.8469 - acc: 0.9449 - val_loss: 344479.2846 - val_acc: 0.9121\n",
      "Epoch 123/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 42624.9440 - acc: 0.9451 - val_loss: 351840.9605 - val_acc: 0.9069\n",
      "Epoch 124/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 42670.7228 - acc: 0.9447 - val_loss: 359524.8369 - val_acc: 0.9042\n",
      "Epoch 125/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 42046.7180 - acc: 0.9459 - val_loss: 384931.9280 - val_acc: 0.8965\n",
      "Epoch 126/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 42160.6422 - acc: 0.9448 - val_loss: 378657.0652 - val_acc: 0.9140\n",
      "Epoch 127/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 41823.0417 - acc: 0.9461 - val_loss: 363501.7899 - val_acc: 0.9072\n",
      "Epoch 128/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 42177.0578 - acc: 0.9457 - val_loss: 364285.3673 - val_acc: 0.9012\n",
      "Epoch 129/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 41420.1429 - acc: 0.9462 - val_loss: 347878.1558 - val_acc: 0.9123\n",
      "Epoch 130/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 41564.4905 - acc: 0.9454 - val_loss: 372455.2263 - val_acc: 0.8994\n",
      "Epoch 131/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 41390.1256 - acc: 0.9457 - val_loss: 352420.4718 - val_acc: 0.9096\n",
      "Epoch 132/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 41461.0324 - acc: 0.9453 - val_loss: 370897.1048 - val_acc: 0.9030\n",
      "Epoch 133/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 40860.7749 - acc: 0.9463 - val_loss: 357257.7277 - val_acc: 0.9110\n",
      "Epoch 134/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 40609.9541 - acc: 0.9471 - val_loss: 381107.0478 - val_acc: 0.9039\n",
      "Epoch 135/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 40831.6063 - acc: 0.9455 - val_loss: 382244.7412 - val_acc: 0.9002\n",
      "Epoch 136/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 40335.1477 - acc: 0.9473 - val_loss: 383625.2045 - val_acc: 0.9067\n",
      "Epoch 137/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 40513.3551 - acc: 0.9466 - val_loss: 342422.9739 - val_acc: 0.9090\n",
      "Epoch 138/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 40437.8994 - acc: 0.9466 - val_loss: 383117.3415 - val_acc: 0.9081\n",
      "Epoch 139/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 40040.1275 - acc: 0.9463 - val_loss: 410510.3659 - val_acc: 0.9112\n",
      "Epoch 140/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 40347.1518 - acc: 0.9479 - val_loss: 392582.4195 - val_acc: 0.9115\n",
      "Epoch 141/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 39612.0006 - acc: 0.9472 - val_loss: 396996.8628 - val_acc: 0.9036\n",
      "Epoch 142/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 39911.5524 - acc: 0.9480 - val_loss: 366865.0318 - val_acc: 0.9059\n",
      "Epoch 143/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 39864.6204 - acc: 0.9473 - val_loss: 372491.2352 - val_acc: 0.9079\n",
      "Epoch 144/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 39732.3503 - acc: 0.9475 - val_loss: 377008.0822 - val_acc: 0.9078\n",
      "Epoch 145/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 39054.5760 - acc: 0.9482 - val_loss: 404455.6874 - val_acc: 0.9074\n",
      "Epoch 146/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 39216.7171 - acc: 0.9480 - val_loss: 376985.3348 - val_acc: 0.9024\n",
      "Epoch 147/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 39071.6969 - acc: 0.9484 - val_loss: 372407.2869 - val_acc: 0.9011\n",
      "Epoch 148/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 39392.4849 - acc: 0.9483 - val_loss: 373971.8355 - val_acc: 0.9027\n",
      "Epoch 149/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 39418.4806 - acc: 0.9486 - val_loss: 383544.6873 - val_acc: 0.8991\n",
      "Epoch 150/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 38779.6425 - acc: 0.9497 - val_loss: 389023.3811 - val_acc: 0.9146\n",
      "Epoch 151/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 39191.5648 - acc: 0.9486 - val_loss: 368832.4694 - val_acc: 0.9074\n",
      "Epoch 152/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 38290.0009 - acc: 0.9485 - val_loss: 374671.4619 - val_acc: 0.9007\n",
      "Epoch 153/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 38521.2353 - acc: 0.9472 - val_loss: 380630.5936 - val_acc: 0.9064\n",
      "Epoch 154/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 37972.8814 - acc: 0.9492 - val_loss: 387568.3651 - val_acc: 0.9081\n",
      "Epoch 155/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 38216.5864 - acc: 0.9489 - val_loss: 380122.2916 - val_acc: 0.9049\n",
      "Epoch 156/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 38254.3058 - acc: 0.9483 - val_loss: 404249.2663 - val_acc: 0.9089\n",
      "Epoch 157/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 37601.4029 - acc: 0.9492 - val_loss: 395769.3738 - val_acc: 0.9063\n",
      "Epoch 158/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 37979.8665 - acc: 0.9480 - val_loss: 382560.2987 - val_acc: 0.9089\n",
      "Epoch 159/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 38012.1622 - acc: 0.9481 - val_loss: 360012.8702 - val_acc: 0.9054\n",
      "Epoch 160/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 37474.6754 - acc: 0.9483 - val_loss: 378830.0222 - val_acc: 0.9128\n",
      "Epoch 161/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 37283.9667 - acc: 0.9484 - val_loss: 371284.1339 - val_acc: 0.9021\n",
      "Epoch 162/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 37531.0304 - acc: 0.9500 - val_loss: 392487.1059 - val_acc: 0.9060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 36974.1109 - acc: 0.9491 - val_loss: 380633.6863 - val_acc: 0.9037\n",
      "Epoch 164/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 36870.1952 - acc: 0.9502 - val_loss: 377894.9070 - val_acc: 0.9081\n",
      "Epoch 165/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 37071.7465 - acc: 0.9502 - val_loss: 400604.9243 - val_acc: 0.9051\n",
      "Epoch 166/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 37033.1898 - acc: 0.9504 - val_loss: 393034.3653 - val_acc: 0.9115\n",
      "Epoch 167/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 36756.0519 - acc: 0.9495 - val_loss: 414836.2022 - val_acc: 0.9103\n",
      "Epoch 168/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 36679.1568 - acc: 0.9498 - val_loss: 382148.4464 - val_acc: 0.9074\n",
      "Epoch 169/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 36140.3039 - acc: 0.9489 - val_loss: 397765.4053 - val_acc: 0.9126\n",
      "Epoch 170/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 36953.6015 - acc: 0.9494 - val_loss: 414115.4499 - val_acc: 0.8983\n",
      "Epoch 171/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 36701.6669 - acc: 0.9497 - val_loss: 387457.8436 - val_acc: 0.9084\n",
      "Epoch 172/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 35861.4554 - acc: 0.9509 - val_loss: 378193.2536 - val_acc: 0.9121\n",
      "Epoch 173/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 35867.4803 - acc: 0.9498 - val_loss: 375889.4614 - val_acc: 0.9108\n",
      "Epoch 174/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 36063.7275 - acc: 0.9499 - val_loss: 412351.9232 - val_acc: 0.9026\n",
      "Epoch 175/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 36483.2200 - acc: 0.9492 - val_loss: 408352.4042 - val_acc: 0.9066\n",
      "Epoch 176/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 35644.1999 - acc: 0.9499 - val_loss: 400429.1818 - val_acc: 0.9096\n",
      "Epoch 177/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 36112.4951 - acc: 0.9498 - val_loss: 410194.1461 - val_acc: 0.9147\n",
      "Epoch 178/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 35577.1151 - acc: 0.9493 - val_loss: 363112.0118 - val_acc: 0.9071\n",
      "Epoch 179/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 36022.4882 - acc: 0.9497 - val_loss: 375664.5642 - val_acc: 0.9070\n",
      "Epoch 180/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 35579.8400 - acc: 0.9506 - val_loss: 418052.2558 - val_acc: 0.9043\n",
      "Epoch 181/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 35541.8573 - acc: 0.9504 - val_loss: 405797.6804 - val_acc: 0.9099\n",
      "Epoch 182/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 35186.8734 - acc: 0.9510 - val_loss: 399205.7051 - val_acc: 0.9062\n",
      "Epoch 183/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 35089.5176 - acc: 0.9504 - val_loss: 414086.3385 - val_acc: 0.9062\n",
      "Epoch 184/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 35236.6151 - acc: 0.9506 - val_loss: 407467.7613 - val_acc: 0.9097\n",
      "Epoch 185/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 35141.3438 - acc: 0.9504 - val_loss: 413192.3692 - val_acc: 0.9072\n",
      "Epoch 186/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 35105.1602 - acc: 0.9511 - val_loss: 396977.7709 - val_acc: 0.9072\n",
      "Epoch 187/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 34838.4560 - acc: 0.9516 - val_loss: 424389.0410 - val_acc: 0.9071\n",
      "Epoch 188/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 34741.0483 - acc: 0.9516 - val_loss: 398747.6338 - val_acc: 0.9081\n",
      "Epoch 189/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 34989.0328 - acc: 0.9509 - val_loss: 422724.6884 - val_acc: 0.9013\n",
      "Epoch 190/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 35356.4950 - acc: 0.9506 - val_loss: 405692.3591 - val_acc: 0.9076\n",
      "Epoch 191/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 34691.8422 - acc: 0.9521 - val_loss: 405662.4413 - val_acc: 0.9090\n",
      "Epoch 192/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 34089.4461 - acc: 0.9523 - val_loss: 384784.3122 - val_acc: 0.9083\n",
      "Epoch 193/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 34431.4539 - acc: 0.9508 - val_loss: 395413.6084 - val_acc: 0.9057\n",
      "Epoch 194/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 34075.3525 - acc: 0.9520 - val_loss: 408691.2857 - val_acc: 0.9093\n",
      "Epoch 195/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 34233.9698 - acc: 0.9511 - val_loss: 418251.3730 - val_acc: 0.9103\n",
      "Epoch 196/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 34521.9925 - acc: 0.9519 - val_loss: 419345.7945 - val_acc: 0.9076\n",
      "Epoch 197/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 34609.2105 - acc: 0.9504 - val_loss: 415443.9445 - val_acc: 0.8958\n",
      "Epoch 198/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 33959.2946 - acc: 0.9519 - val_loss: 424353.1635 - val_acc: 0.9058\n",
      "Epoch 199/1000\n",
      "63424/63424 [==============================] - 3s 43us/sample - loss: 33832.4305 - acc: 0.9521 - val_loss: 413756.3734 - val_acc: 0.9081\n",
      "Epoch 200/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 33586.8371 - acc: 0.9527 - val_loss: 402645.7337 - val_acc: 0.9024\n",
      "Epoch 201/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 34123.8975 - acc: 0.9514 - val_loss: 407173.2310 - val_acc: 0.9126\n",
      "Epoch 202/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 33627.2809 - acc: 0.9523 - val_loss: 401044.1678 - val_acc: 0.9123\n",
      "Epoch 203/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 33751.6151 - acc: 0.9515 - val_loss: 432160.2525 - val_acc: 0.9068\n",
      "Epoch 204/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 33360.4417 - acc: 0.9519 - val_loss: 437254.4638 - val_acc: 0.9001\n",
      "Epoch 205/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 33212.0149 - acc: 0.9531 - val_loss: 422340.3956 - val_acc: 0.9073\n",
      "Epoch 206/1000\n",
      "63424/63424 [==============================] - 3s 43us/sample - loss: 33513.1956 - acc: 0.9521 - val_loss: 439744.5515 - val_acc: 0.9118\n",
      "Epoch 207/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32912.5308 - acc: 0.9527 - val_loss: 419770.6455 - val_acc: 0.9051\n",
      "Epoch 208/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 33017.3583 - acc: 0.9524 - val_loss: 412641.5536 - val_acc: 0.9009\n",
      "Epoch 209/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 33068.8744 - acc: 0.9524 - val_loss: 403999.9063 - val_acc: 0.9093\n",
      "Epoch 210/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32893.6842 - acc: 0.9530 - val_loss: 469854.4150 - val_acc: 0.8949\n",
      "Epoch 211/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32837.6908 - acc: 0.9522 - val_loss: 435629.1209 - val_acc: 0.9061\n",
      "Epoch 212/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32491.8357 - acc: 0.9538 - val_loss: 427069.0628 - val_acc: 0.9118\n",
      "Epoch 213/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32987.6769 - acc: 0.9528 - val_loss: 414015.6644 - val_acc: 0.9084\n",
      "Epoch 214/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32977.3910 - acc: 0.9522 - val_loss: 433603.8375 - val_acc: 0.9000\n",
      "Epoch 215/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 33211.8850 - acc: 0.9510 - val_loss: 426959.4839 - val_acc: 0.9124\n",
      "Epoch 216/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32184.7741 - acc: 0.9535 - val_loss: 425616.8768 - val_acc: 0.9112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32466.1051 - acc: 0.9527 - val_loss: 430527.6491 - val_acc: 0.9116\n",
      "Epoch 218/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 32547.3549 - acc: 0.9525 - val_loss: 416232.7488 - val_acc: 0.9064\n",
      "Epoch 219/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32420.7391 - acc: 0.9527 - val_loss: 425897.6454 - val_acc: 0.9026\n",
      "Epoch 220/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32040.8286 - acc: 0.9532 - val_loss: 395423.1576 - val_acc: 0.9064\n",
      "Epoch 221/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32266.5106 - acc: 0.9532 - val_loss: 429123.8431 - val_acc: 0.9034\n",
      "Epoch 222/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32127.7589 - acc: 0.9533 - val_loss: 422661.3402 - val_acc: 0.9086\n",
      "Epoch 223/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 32440.2950 - acc: 0.9527 - val_loss: 414751.2767 - val_acc: 0.9067\n",
      "Epoch 224/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 31744.2201 - acc: 0.9536 - val_loss: 394426.5087 - val_acc: 0.9056\n",
      "Epoch 225/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 32181.7785 - acc: 0.9533 - val_loss: 428194.7952 - val_acc: 0.9081\n",
      "Epoch 226/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 31850.8939 - acc: 0.9538 - val_loss: 411620.0870 - val_acc: 0.9028\n",
      "Epoch 227/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 31981.2552 - acc: 0.9523 - val_loss: 436205.2163 - val_acc: 0.9083\n",
      "Epoch 228/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 31797.2971 - acc: 0.9537 - val_loss: 415212.9493 - val_acc: 0.9052\n",
      "Epoch 229/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 31373.3564 - acc: 0.9538 - val_loss: 435115.3247 - val_acc: 0.9122\n",
      "Epoch 230/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 31873.1939 - acc: 0.9525 - val_loss: 407970.2695 - val_acc: 0.9083\n",
      "Epoch 231/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 31612.2120 - acc: 0.9541 - val_loss: 411495.4946 - val_acc: 0.9099\n",
      "Epoch 232/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 31434.9000 - acc: 0.9540 - val_loss: 434836.7725 - val_acc: 0.9077\n",
      "Epoch 233/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 31870.1375 - acc: 0.9532 - val_loss: 414830.5579 - val_acc: 0.9053\n",
      "Epoch 234/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 31340.3130 - acc: 0.9537 - val_loss: 422556.6536 - val_acc: 0.9122\n",
      "Epoch 235/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 31427.3573 - acc: 0.9529 - val_loss: 419226.9569 - val_acc: 0.9100\n",
      "Epoch 236/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 31033.2811 - acc: 0.9538 - val_loss: 411270.3615 - val_acc: 0.9038\n",
      "Epoch 237/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 31477.9827 - acc: 0.9543 - val_loss: 439311.6264 - val_acc: 0.9078\n",
      "Epoch 238/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 31437.5361 - acc: 0.9536 - val_loss: 409740.2754 - val_acc: 0.9043\n",
      "Epoch 239/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30734.3634 - acc: 0.9543 - val_loss: 440657.5560 - val_acc: 0.9030\n",
      "Epoch 240/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 31354.1081 - acc: 0.9533 - val_loss: 427599.1595 - val_acc: 0.9090\n",
      "Epoch 241/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30711.6950 - acc: 0.9541 - val_loss: 445022.7477 - val_acc: 0.9070\n",
      "Epoch 242/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 30829.3498 - acc: 0.9539 - val_loss: 432571.7817 - val_acc: 0.9123\n",
      "Epoch 243/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 30435.8951 - acc: 0.9547 - val_loss: 429515.4929 - val_acc: 0.9138\n",
      "Epoch 244/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30812.5388 - acc: 0.9539 - val_loss: 434189.5470 - val_acc: 0.9060\n",
      "Epoch 245/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30713.7902 - acc: 0.9549 - val_loss: 420089.9756 - val_acc: 0.9019\n",
      "Epoch 246/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30743.9570 - acc: 0.9542 - val_loss: 453535.9023 - val_acc: 0.9133\n",
      "Epoch 247/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30543.8652 - acc: 0.9546 - val_loss: 402493.7723 - val_acc: 0.9114\n",
      "Epoch 248/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 31008.1381 - acc: 0.9542 - val_loss: 437662.7912 - val_acc: 0.9075\n",
      "Epoch 249/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30358.9366 - acc: 0.9553 - val_loss: 429499.0434 - val_acc: 0.9124\n",
      "Epoch 250/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30383.6168 - acc: 0.9543 - val_loss: 426672.4623 - val_acc: 0.9023\n",
      "Epoch 251/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30628.6811 - acc: 0.9540 - val_loss: 439644.2525 - val_acc: 0.9108\n",
      "Epoch 252/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 30002.6834 - acc: 0.9547 - val_loss: 435190.1175 - val_acc: 0.9103\n",
      "Epoch 253/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30058.7608 - acc: 0.9555 - val_loss: 442359.1926 - val_acc: 0.9091\n",
      "Epoch 254/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30555.7456 - acc: 0.9548 - val_loss: 426965.8693 - val_acc: 0.9051\n",
      "Epoch 255/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30233.6146 - acc: 0.9543 - val_loss: 425392.4834 - val_acc: 0.9073\n",
      "Epoch 256/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29926.4930 - acc: 0.9563 - val_loss: 427438.7693 - val_acc: 0.9089\n",
      "Epoch 257/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30484.8345 - acc: 0.9541 - val_loss: 416012.6356 - val_acc: 0.9096\n",
      "Epoch 258/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30111.6631 - acc: 0.9542 - val_loss: 437703.2148 - val_acc: 0.9109\n",
      "Epoch 259/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29791.4596 - acc: 0.9555 - val_loss: 439260.7067 - val_acc: 0.9086\n",
      "Epoch 260/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30647.3214 - acc: 0.9544 - val_loss: 430957.9284 - val_acc: 0.9087\n",
      "Epoch 261/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 30081.3867 - acc: 0.9555 - val_loss: 430517.9021 - val_acc: 0.9007\n",
      "Epoch 262/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29969.9959 - acc: 0.9550 - val_loss: 414633.0251 - val_acc: 0.9149\n",
      "Epoch 263/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29546.7302 - acc: 0.9550 - val_loss: 429169.3488 - val_acc: 0.9155\n",
      "Epoch 264/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 29939.3690 - acc: 0.9547 - val_loss: 425142.4420 - val_acc: 0.9116\n",
      "Epoch 265/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29946.0718 - acc: 0.9542 - val_loss: 434178.0948 - val_acc: 0.9133\n",
      "Epoch 266/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29613.8058 - acc: 0.9556 - val_loss: 439693.2681 - val_acc: 0.9119\n",
      "Epoch 267/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29611.3373 - acc: 0.9554 - val_loss: 442804.1743 - val_acc: 0.9020\n",
      "Epoch 268/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29878.0768 - acc: 0.9555 - val_loss: 433441.1014 - val_acc: 0.9076\n",
      "Epoch 269/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29849.5730 - acc: 0.9553 - val_loss: 453246.3922 - val_acc: 0.9047\n",
      "Epoch 270/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29470.7734 - acc: 0.9557 - val_loss: 430679.4112 - val_acc: 0.9064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 29254.1616 - acc: 0.9568 - val_loss: 435869.3950 - val_acc: 0.9066\n",
      "Epoch 272/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29715.6339 - acc: 0.9554 - val_loss: 445996.1436 - val_acc: 0.9109\n",
      "Epoch 273/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29311.6417 - acc: 0.9566 - val_loss: 433491.9882 - val_acc: 0.9081\n",
      "Epoch 274/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29296.5558 - acc: 0.9560 - val_loss: 440354.5260 - val_acc: 0.9085\n",
      "Epoch 275/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 29117.2516 - acc: 0.9562 - val_loss: 436757.7100 - val_acc: 0.9116\n",
      "Epoch 276/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 29147.5410 - acc: 0.9556 - val_loss: 435497.5924 - val_acc: 0.9076\n",
      "Epoch 277/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 29125.9285 - acc: 0.9553 - val_loss: 440644.7637 - val_acc: 0.9152\n",
      "Epoch 278/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 29576.8666 - acc: 0.9558 - val_loss: 432740.6476 - val_acc: 0.9074\n",
      "Epoch 279/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 28954.3023 - acc: 0.9558 - val_loss: 449145.4045 - val_acc: 0.9160\n",
      "Epoch 280/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 28888.5064 - acc: 0.9554 - val_loss: 462306.9741 - val_acc: 0.9156\n",
      "Epoch 281/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 28745.3511 - acc: 0.9561 - val_loss: 432049.0737 - val_acc: 0.9116\n",
      "Epoch 282/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 29300.1348 - acc: 0.9565 - val_loss: 428988.6878 - val_acc: 0.9102\n",
      "Epoch 283/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28997.8306 - acc: 0.9559 - val_loss: 443128.3837 - val_acc: 0.9137\n",
      "Epoch 284/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28784.7357 - acc: 0.9562 - val_loss: 450917.0073 - val_acc: 0.9104\n",
      "Epoch 285/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28619.0701 - acc: 0.9563 - val_loss: 437224.5859 - val_acc: 0.9107\n",
      "Epoch 286/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 29002.1855 - acc: 0.9556 - val_loss: 433565.5504 - val_acc: 0.9101\n",
      "Epoch 287/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28706.5345 - acc: 0.9550 - val_loss: 441834.1096 - val_acc: 0.9111\n",
      "Epoch 288/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28788.4532 - acc: 0.9564 - val_loss: 414761.2985 - val_acc: 0.9105\n",
      "Epoch 289/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28626.9285 - acc: 0.9573 - val_loss: 451110.7424 - val_acc: 0.9081\n",
      "Epoch 290/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28504.0039 - acc: 0.9565 - val_loss: 433258.0182 - val_acc: 0.9090\n",
      "Epoch 291/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28865.8685 - acc: 0.9559 - val_loss: 420078.1417 - val_acc: 0.9138\n",
      "Epoch 292/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 28190.8797 - acc: 0.9572 - val_loss: 471805.9412 - val_acc: 0.9128\n",
      "Epoch 293/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28516.4820 - acc: 0.9562 - val_loss: 494989.6060 - val_acc: 0.9139\n",
      "Epoch 294/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28810.7533 - acc: 0.9567 - val_loss: 439654.4538 - val_acc: 0.9067\n",
      "Epoch 295/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28224.8091 - acc: 0.9564 - val_loss: 454080.6584 - val_acc: 0.9087\n",
      "Epoch 296/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28268.9663 - acc: 0.9566 - val_loss: 424648.9672 - val_acc: 0.9131\n",
      "Epoch 297/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28273.2459 - acc: 0.9579 - val_loss: 440391.4701 - val_acc: 0.9130\n",
      "Epoch 298/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28402.3113 - acc: 0.9570 - val_loss: 434867.5747 - val_acc: 0.9071\n",
      "Epoch 299/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28140.7036 - acc: 0.9563 - val_loss: 448395.1693 - val_acc: 0.9052\n",
      "Epoch 300/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28287.0782 - acc: 0.9568 - val_loss: 435358.7531 - val_acc: 0.9112\n",
      "Epoch 301/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 28225.4372 - acc: 0.9559 - val_loss: 432704.8217 - val_acc: 0.9059\n",
      "Epoch 302/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28023.3535 - acc: 0.9565 - val_loss: 455613.3066 - val_acc: 0.9045\n",
      "Epoch 303/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 28447.5751 - acc: 0.9569 - val_loss: 450546.8131 - val_acc: 0.9097\n",
      "Epoch 304/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28484.1850 - acc: 0.9561 - val_loss: 433368.0335 - val_acc: 0.9092\n",
      "Epoch 305/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27876.8184 - acc: 0.9582 - val_loss: 472547.6629 - val_acc: 0.9003\n",
      "Epoch 306/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 28142.6937 - acc: 0.9572 - val_loss: 450956.5621 - val_acc: 0.9030\n",
      "Epoch 307/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27901.7351 - acc: 0.9572 - val_loss: 437554.7275 - val_acc: 0.9098\n",
      "Epoch 308/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27865.3140 - acc: 0.9571 - val_loss: 450467.8588 - val_acc: 0.9064\n",
      "Epoch 309/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27943.8945 - acc: 0.9579 - val_loss: 453351.9591 - val_acc: 0.9121\n",
      "Epoch 310/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27716.8418 - acc: 0.9557 - val_loss: 446656.8321 - val_acc: 0.9124\n",
      "Epoch 311/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27556.3182 - acc: 0.9580 - val_loss: 480105.5664 - val_acc: 0.9071\n",
      "Epoch 312/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27686.2253 - acc: 0.9570 - val_loss: 469736.1022 - val_acc: 0.9110\n",
      "Epoch 313/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 28060.3933 - acc: 0.9582 - val_loss: 482730.6424 - val_acc: 0.9080\n",
      "Epoch 314/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27745.9672 - acc: 0.9575 - val_loss: 464897.2391 - val_acc: 0.9117\n",
      "Epoch 315/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27638.5994 - acc: 0.9577 - val_loss: 473183.8460 - val_acc: 0.9142\n",
      "Epoch 316/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27606.9691 - acc: 0.9568 - val_loss: 448792.0760 - val_acc: 0.9046\n",
      "Epoch 317/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27400.7602 - acc: 0.9570 - val_loss: 433212.8246 - val_acc: 0.8989\n",
      "Epoch 318/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27437.7291 - acc: 0.9572 - val_loss: 446729.5223 - val_acc: 0.9119\n",
      "Epoch 319/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27936.0296 - acc: 0.9564 - val_loss: 454184.6502 - val_acc: 0.9075\n",
      "Epoch 320/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27845.6241 - acc: 0.9568 - val_loss: 453133.8641 - val_acc: 0.9092\n",
      "Epoch 321/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27391.6826 - acc: 0.9585 - val_loss: 473302.3179 - val_acc: 0.9018\n",
      "Epoch 322/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27043.6594 - acc: 0.9566 - val_loss: 440048.7887 - val_acc: 0.9002\n",
      "Epoch 323/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27906.5239 - acc: 0.9565 - val_loss: 448740.9884 - val_acc: 0.9122\n",
      "Epoch 324/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27257.8262 - acc: 0.9579 - val_loss: 452159.9556 - val_acc: 0.9131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27091.3026 - acc: 0.9574 - val_loss: 446595.9811 - val_acc: 0.9087\n",
      "Epoch 326/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27402.9610 - acc: 0.9580 - val_loss: 433641.3491 - val_acc: 0.9078\n",
      "Epoch 327/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27159.3951 - acc: 0.9572 - val_loss: 468128.3883 - val_acc: 0.9150\n",
      "Epoch 328/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27525.2163 - acc: 0.9575 - val_loss: 452705.1696 - val_acc: 0.9116\n",
      "Epoch 329/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27058.8613 - acc: 0.9588 - val_loss: 438992.8614 - val_acc: 0.9059\n",
      "Epoch 330/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 26759.1932 - acc: 0.9579 - val_loss: 456093.6230 - val_acc: 0.9091\n",
      "Epoch 331/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27081.8460 - acc: 0.9579 - val_loss: 442703.4957 - val_acc: 0.9053\n",
      "Epoch 332/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27169.1060 - acc: 0.9580 - val_loss: 428962.5123 - val_acc: 0.9147\n",
      "Epoch 333/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27244.1329 - acc: 0.9572 - val_loss: 466999.7516 - val_acc: 0.9127\n",
      "Epoch 334/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 26816.9770 - acc: 0.9572 - val_loss: 433659.0478 - val_acc: 0.9026\n",
      "Epoch 335/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27157.4888 - acc: 0.9565 - val_loss: 434128.6419 - val_acc: 0.9123\n",
      "Epoch 336/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27135.4888 - acc: 0.9578 - val_loss: 474340.5458 - val_acc: 0.9067\n",
      "Epoch 337/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 26921.0227 - acc: 0.9585 - val_loss: 467823.9376 - val_acc: 0.9094\n",
      "Epoch 338/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 26819.8111 - acc: 0.9575 - val_loss: 455320.2929 - val_acc: 0.9099\n",
      "Epoch 339/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27168.2387 - acc: 0.9579 - val_loss: 465262.6815 - val_acc: 0.9120\n",
      "Epoch 340/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 26765.2193 - acc: 0.9587 - val_loss: 440103.8993 - val_acc: 0.9140\n",
      "Epoch 341/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 26100.1328 - acc: 0.9579 - val_loss: 462366.2662 - val_acc: 0.9081\n",
      "Epoch 342/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26696.9701 - acc: 0.9586 - val_loss: 488762.0868 - val_acc: 0.9037\n",
      "Epoch 343/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 27011.2584 - acc: 0.9584 - val_loss: 433244.6341 - val_acc: 0.9133\n",
      "Epoch 344/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26669.3287 - acc: 0.9571 - val_loss: 453422.1526 - val_acc: 0.9124\n",
      "Epoch 345/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 27016.6067 - acc: 0.9582 - val_loss: 464932.9986 - val_acc: 0.9159\n",
      "Epoch 346/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 26759.3935 - acc: 0.9588 - val_loss: 443524.0165 - val_acc: 0.9152\n",
      "Epoch 347/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26848.7865 - acc: 0.9582 - val_loss: 437388.4618 - val_acc: 0.9122\n",
      "Epoch 348/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26475.9360 - acc: 0.9582 - val_loss: 468934.2296 - val_acc: 0.9094\n",
      "Epoch 349/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26598.5831 - acc: 0.9591 - val_loss: 463306.9986 - val_acc: 0.9065\n",
      "Epoch 350/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26390.8823 - acc: 0.9586 - val_loss: 438880.1282 - val_acc: 0.9091\n",
      "Epoch 351/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 26428.6515 - acc: 0.9585 - val_loss: 460362.2513 - val_acc: 0.9065\n",
      "Epoch 352/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26731.9999 - acc: 0.9584 - val_loss: 467140.2842 - val_acc: 0.9109\n",
      "Epoch 353/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 26560.1901 - acc: 0.9579 - val_loss: 449796.2840 - val_acc: 0.9122\n",
      "Epoch 354/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26050.1034 - acc: 0.9590 - val_loss: 485668.4904 - val_acc: 0.9087\n",
      "Epoch 355/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26619.6768 - acc: 0.9587 - val_loss: 469734.5053 - val_acc: 0.9184\n",
      "Epoch 356/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25984.2126 - acc: 0.9578 - val_loss: 451347.7556 - val_acc: 0.9044\n",
      "Epoch 357/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26272.1777 - acc: 0.9584 - val_loss: 481721.7532 - val_acc: 0.9101\n",
      "Epoch 358/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26700.9954 - acc: 0.9587 - val_loss: 463479.2792 - val_acc: 0.9160\n",
      "Epoch 359/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25649.3553 - acc: 0.9588 - val_loss: 470168.1424 - val_acc: 0.9133\n",
      "Epoch 360/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 26033.7417 - acc: 0.9590 - val_loss: 468651.6909 - val_acc: 0.9168\n",
      "Epoch 361/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25836.0051 - acc: 0.9592 - val_loss: 460547.3619 - val_acc: 0.9154\n",
      "Epoch 362/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26149.4061 - acc: 0.9582 - val_loss: 463313.2489 - val_acc: 0.9108\n",
      "Epoch 363/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25780.5378 - acc: 0.9594 - val_loss: 459810.6284 - val_acc: 0.9148\n",
      "Epoch 364/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25854.5142 - acc: 0.9582 - val_loss: 488770.3931 - val_acc: 0.9124\n",
      "Epoch 365/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25899.0068 - acc: 0.9587 - val_loss: 463448.2496 - val_acc: 0.9131\n",
      "Epoch 366/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26123.8323 - acc: 0.9580 - val_loss: 455300.2024 - val_acc: 0.9120\n",
      "Epoch 367/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26350.0387 - acc: 0.9590 - val_loss: 463288.2032 - val_acc: 0.9118\n",
      "Epoch 368/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25590.7287 - acc: 0.9591 - val_loss: 434765.6116 - val_acc: 0.9145\n",
      "Epoch 369/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25565.0337 - acc: 0.9594 - val_loss: 457231.7166 - val_acc: 0.9078\n",
      "Epoch 370/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25889.7341 - acc: 0.9585 - val_loss: 438052.7967 - val_acc: 0.9125\n",
      "Epoch 371/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 25858.6672 - acc: 0.9591 - val_loss: 476265.8547 - val_acc: 0.9106\n",
      "Epoch 372/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26164.7482 - acc: 0.9586 - val_loss: 452519.2950 - val_acc: 0.9070\n",
      "Epoch 373/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 25612.1846 - acc: 0.9594 - val_loss: 468221.8317 - val_acc: 0.9133\n",
      "Epoch 374/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25709.6520 - acc: 0.9582 - val_loss: 460475.0777 - val_acc: 0.9098\n",
      "Epoch 375/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25787.5530 - acc: 0.9592 - val_loss: 485298.8580 - val_acc: 0.9072\n",
      "Epoch 376/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 26166.2998 - acc: 0.9587 - val_loss: 457760.1578 - val_acc: 0.9087\n",
      "Epoch 377/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25423.1782 - acc: 0.9595 - val_loss: 500537.5386 - val_acc: 0.9149\n",
      "Epoch 378/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25948.6021 - acc: 0.9578 - val_loss: 463428.5160 - val_acc: 0.9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25601.2285 - acc: 0.9591 - val_loss: 475752.8074 - val_acc: 0.9171\n",
      "Epoch 380/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25379.3096 - acc: 0.9597 - val_loss: 496098.6164 - val_acc: 0.9090\n",
      "Epoch 381/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25454.5041 - acc: 0.9591 - val_loss: 469546.4918 - val_acc: 0.9107\n",
      "Epoch 382/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25115.8020 - acc: 0.9594 - val_loss: 473886.1254 - val_acc: 0.9152\n",
      "Epoch 383/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 25282.6947 - acc: 0.9594 - val_loss: 499054.7519 - val_acc: 0.9178\n",
      "Epoch 384/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25101.6183 - acc: 0.9599 - val_loss: 507002.8287 - val_acc: 0.9122\n",
      "Epoch 385/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25607.0880 - acc: 0.9592 - val_loss: 492615.4107 - val_acc: 0.9098\n",
      "Epoch 386/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25146.6314 - acc: 0.9588 - val_loss: 478161.2049 - val_acc: 0.9078\n",
      "Epoch 387/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25372.2297 - acc: 0.9586 - val_loss: 457588.7478 - val_acc: 0.9088\n",
      "Epoch 388/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25344.9534 - acc: 0.9586 - val_loss: 471629.8325 - val_acc: 0.9118\n",
      "Epoch 389/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25427.9542 - acc: 0.9590 - val_loss: 480135.0748 - val_acc: 0.9114\n",
      "Epoch 390/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25060.8061 - acc: 0.9590 - val_loss: 486780.8600 - val_acc: 0.9122\n",
      "Epoch 391/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25545.5119 - acc: 0.9594 - val_loss: 484898.4565 - val_acc: 0.9153\n",
      "Epoch 392/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25250.6800 - acc: 0.9593 - val_loss: 505136.0425 - val_acc: 0.9039\n",
      "Epoch 393/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25245.9102 - acc: 0.9607 - val_loss: 483359.9150 - val_acc: 0.9071\n",
      "Epoch 394/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 25174.3550 - acc: 0.9590 - val_loss: 474943.6218 - val_acc: 0.9111\n",
      "Epoch 395/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 25285.1357 - acc: 0.9591 - val_loss: 486836.5979 - val_acc: 0.9153\n",
      "Epoch 396/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 24857.2964 - acc: 0.9606 - val_loss: 494701.5248 - val_acc: 0.9089\n",
      "Epoch 397/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25278.6983 - acc: 0.9596 - val_loss: 481953.3346 - val_acc: 0.9058\n",
      "Epoch 398/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25231.5588 - acc: 0.9604 - val_loss: 474457.1642 - val_acc: 0.9157\n",
      "Epoch 399/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25061.9958 - acc: 0.9592 - val_loss: 498787.5942 - val_acc: 0.9132\n",
      "Epoch 400/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25117.2105 - acc: 0.9601 - val_loss: 474181.6920 - val_acc: 0.8989\n",
      "Epoch 401/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25006.3457 - acc: 0.9595 - val_loss: 478608.5386 - val_acc: 0.9153\n",
      "Epoch 402/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24836.6324 - acc: 0.9602 - val_loss: 473035.9796 - val_acc: 0.9113\n",
      "Epoch 403/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24767.9985 - acc: 0.9592 - val_loss: 478826.3280 - val_acc: 0.9144\n",
      "Epoch 404/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24994.4798 - acc: 0.9612 - val_loss: 474941.7041 - val_acc: 0.9165\n",
      "Epoch 405/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 25084.2428 - acc: 0.9591 - val_loss: 494560.0644 - val_acc: 0.9153\n",
      "Epoch 406/1000\n",
      "63424/63424 [==============================] - 3s 44us/sample - loss: 24704.4646 - acc: 0.9607 - val_loss: 497306.4430 - val_acc: 0.9081\n",
      "Epoch 407/1000\n",
      "63424/63424 [==============================] - 3s 44us/sample - loss: 24444.3905 - acc: 0.9600 - val_loss: 484267.6512 - val_acc: 0.9114\n",
      "Epoch 408/1000\n",
      "63424/63424 [==============================] - 3s 43us/sample - loss: 25032.4778 - acc: 0.9596 - val_loss: 484551.2139 - val_acc: 0.9106\n",
      "Epoch 409/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24882.8332 - acc: 0.9599 - val_loss: 478172.0765 - val_acc: 0.9105\n",
      "Epoch 410/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24458.3074 - acc: 0.9614 - val_loss: 502932.5371 - val_acc: 0.9069\n",
      "Epoch 411/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24960.7778 - acc: 0.9599 - val_loss: 493310.3430 - val_acc: 0.9130\n",
      "Epoch 412/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24651.1869 - acc: 0.9610 - val_loss: 458912.8927 - val_acc: 0.9108\n",
      "Epoch 413/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 25054.6450 - acc: 0.9605 - val_loss: 462739.3405 - val_acc: 0.9111\n",
      "Epoch 414/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24850.3882 - acc: 0.9602 - val_loss: 484587.3510 - val_acc: 0.9121\n",
      "Epoch 415/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24483.2509 - acc: 0.9596 - val_loss: 480020.7432 - val_acc: 0.9127\n",
      "Epoch 416/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24480.0879 - acc: 0.9599 - val_loss: 486023.5784 - val_acc: 0.9177\n",
      "Epoch 417/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24694.7456 - acc: 0.9597 - val_loss: 485077.1424 - val_acc: 0.9116\n",
      "Epoch 418/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24783.9398 - acc: 0.9608 - val_loss: 463709.4160 - val_acc: 0.9114\n",
      "Epoch 419/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24447.4342 - acc: 0.9604 - val_loss: 495197.4527 - val_acc: 0.9139\n",
      "Epoch 420/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24324.1366 - acc: 0.9598 - val_loss: 487379.3837 - val_acc: 0.9150\n",
      "Epoch 421/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24435.3457 - acc: 0.9599 - val_loss: 448315.2070 - val_acc: 0.9134\n",
      "Epoch 422/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24403.6720 - acc: 0.9603 - val_loss: 487183.8596 - val_acc: 0.9072\n",
      "Epoch 423/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24399.5246 - acc: 0.9608 - val_loss: 471380.7316 - val_acc: 0.9111\n",
      "Epoch 424/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24183.0074 - acc: 0.9603 - val_loss: 481971.4378 - val_acc: 0.9129\n",
      "Epoch 425/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24679.2727 - acc: 0.9602 - val_loss: 490313.6338 - val_acc: 0.9116\n",
      "Epoch 426/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24304.4533 - acc: 0.9597 - val_loss: 484592.6437 - val_acc: 0.9076\n",
      "Epoch 427/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24644.2962 - acc: 0.9607 - val_loss: 495185.1095 - val_acc: 0.9203\n",
      "Epoch 428/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24135.7744 - acc: 0.9616 - val_loss: 481416.5772 - val_acc: 0.9074\n",
      "Epoch 429/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24724.4524 - acc: 0.9603 - val_loss: 505856.7465 - val_acc: 0.9166\n",
      "Epoch 430/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24597.0713 - acc: 0.9605 - val_loss: 493520.3098 - val_acc: 0.9103\n",
      "Epoch 431/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24275.9265 - acc: 0.9609 - val_loss: 475543.4676 - val_acc: 0.9156\n",
      "Epoch 432/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24444.9275 - acc: 0.9604 - val_loss: 476364.5719 - val_acc: 0.9109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 23933.7036 - acc: 0.9613 - val_loss: 463588.6544 - val_acc: 0.9146\n",
      "Epoch 434/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24196.2416 - acc: 0.9608 - val_loss: 478978.6498 - val_acc: 0.9095\n",
      "Epoch 435/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24100.1739 - acc: 0.9613 - val_loss: 460171.3266 - val_acc: 0.9130\n",
      "Epoch 436/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23971.4357 - acc: 0.9614 - val_loss: 482617.8986 - val_acc: 0.9074\n",
      "Epoch 437/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24148.8461 - acc: 0.9609 - val_loss: 486387.2940 - val_acc: 0.9089\n",
      "Epoch 438/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23624.0660 - acc: 0.9608 - val_loss: 487914.9173 - val_acc: 0.9086\n",
      "Epoch 439/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23889.9629 - acc: 0.9615 - val_loss: 477202.2596 - val_acc: 0.9106\n",
      "Epoch 440/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24703.7376 - acc: 0.9606 - val_loss: 495470.1328 - val_acc: 0.9052\n",
      "Epoch 441/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 23502.1036 - acc: 0.9611 - val_loss: 485916.0309 - val_acc: 0.9077\n",
      "Epoch 442/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 24195.1526 - acc: 0.9602 - val_loss: 481299.1968 - val_acc: 0.9130\n",
      "Epoch 443/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23812.2275 - acc: 0.9611 - val_loss: 491848.2040 - val_acc: 0.9021\n",
      "Epoch 444/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23903.7929 - acc: 0.9608 - val_loss: 481623.3237 - val_acc: 0.9133\n",
      "Epoch 445/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23713.9622 - acc: 0.9608 - val_loss: 451443.5916 - val_acc: 0.9109\n",
      "Epoch 446/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24121.3061 - acc: 0.9605 - val_loss: 485620.2766 - val_acc: 0.9175\n",
      "Epoch 447/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23974.5588 - acc: 0.9599 - val_loss: 504776.6818 - val_acc: 0.9154\n",
      "Epoch 448/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24460.5555 - acc: 0.9596 - val_loss: 476040.9761 - val_acc: 0.9126\n",
      "Epoch 449/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23506.6939 - acc: 0.9615 - val_loss: 479715.3190 - val_acc: 0.9141\n",
      "Epoch 450/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 24059.4241 - acc: 0.9600 - val_loss: 474337.5533 - val_acc: 0.9170\n",
      "Epoch 451/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23721.2078 - acc: 0.9611 - val_loss: 482828.1040 - val_acc: 0.9132\n",
      "Epoch 452/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23713.1799 - acc: 0.9611 - val_loss: 464622.1091 - val_acc: 0.9131\n",
      "Epoch 453/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23692.7992 - acc: 0.9618 - val_loss: 467914.5177 - val_acc: 0.9130\n",
      "Epoch 454/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23877.7633 - acc: 0.9612 - val_loss: 450558.1293 - val_acc: 0.9102\n",
      "Epoch 455/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23363.7732 - acc: 0.9617 - val_loss: 470909.0465 - val_acc: 0.9112\n",
      "Epoch 456/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23711.2673 - acc: 0.9614 - val_loss: 495611.9815 - val_acc: 0.9139\n",
      "Epoch 457/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23630.9250 - acc: 0.9606 - val_loss: 506131.5186 - val_acc: 0.9145\n",
      "Epoch 458/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23552.9740 - acc: 0.9603 - val_loss: 480314.8956 - val_acc: 0.9107\n",
      "Epoch 459/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23673.5535 - acc: 0.9617 - val_loss: 498692.4389 - val_acc: 0.9121\n",
      "Epoch 460/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23722.7956 - acc: 0.9611 - val_loss: 484387.9726 - val_acc: 0.9179\n",
      "Epoch 461/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 23661.7471 - acc: 0.9615 - val_loss: 507927.4136 - val_acc: 0.9096\n",
      "Epoch 462/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 23224.9843 - acc: 0.9606 - val_loss: 495815.6005 - val_acc: 0.9119\n",
      "Epoch 463/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23522.7633 - acc: 0.9618 - val_loss: 480448.4327 - val_acc: 0.9130\n",
      "Epoch 464/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23843.3276 - acc: 0.9608 - val_loss: 486517.7722 - val_acc: 0.9134\n",
      "Epoch 465/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23530.8015 - acc: 0.9617 - val_loss: 481685.6613 - val_acc: 0.9102\n",
      "Epoch 466/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23364.3794 - acc: 0.9620 - val_loss: 501378.0101 - val_acc: 0.9131\n",
      "Epoch 467/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23969.0100 - acc: 0.9603 - val_loss: 490510.3723 - val_acc: 0.9145\n",
      "Epoch 468/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23521.1941 - acc: 0.9606 - val_loss: 496177.2037 - val_acc: 0.9165\n",
      "Epoch 469/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23096.8143 - acc: 0.9617 - val_loss: 490516.1829 - val_acc: 0.9114\n",
      "Epoch 470/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 23220.7721 - acc: 0.9610 - val_loss: 522872.6820 - val_acc: 0.9149\n",
      "Epoch 471/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23470.7804 - acc: 0.9613 - val_loss: 507288.2446 - val_acc: 0.9140\n",
      "Epoch 472/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23764.5127 - acc: 0.9610 - val_loss: 480022.5641 - val_acc: 0.9148\n",
      "Epoch 473/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23332.4632 - acc: 0.9623 - val_loss: 489715.6555 - val_acc: 0.9117\n",
      "Epoch 474/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23295.5350 - acc: 0.9618 - val_loss: 492978.1593 - val_acc: 0.9101\n",
      "Epoch 475/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22629.1584 - acc: 0.9620 - val_loss: 484836.4775 - val_acc: 0.9133\n",
      "Epoch 476/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23578.7116 - acc: 0.9608 - val_loss: 492204.6130 - val_acc: 0.9059\n",
      "Epoch 477/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23234.0701 - acc: 0.9617 - val_loss: 489727.7743 - val_acc: 0.9121\n",
      "Epoch 478/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23069.2133 - acc: 0.9621 - val_loss: 476632.9423 - val_acc: 0.9070\n",
      "Epoch 479/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23458.9049 - acc: 0.9602 - val_loss: 482872.0772 - val_acc: 0.9133\n",
      "Epoch 480/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23275.2328 - acc: 0.9608 - val_loss: 500947.8529 - val_acc: 0.9175\n",
      "Epoch 481/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23578.8000 - acc: 0.9613 - val_loss: 467037.6961 - val_acc: 0.9044\n",
      "Epoch 482/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 23171.5360 - acc: 0.9615 - val_loss: 476416.6199 - val_acc: 0.9127\n",
      "Epoch 483/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23274.8731 - acc: 0.9609 - val_loss: 510758.8129 - val_acc: 0.9101\n",
      "Epoch 484/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23118.8256 - acc: 0.9618 - val_loss: 462722.0160 - val_acc: 0.9035\n",
      "Epoch 485/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23458.5072 - acc: 0.9611 - val_loss: 494436.9720 - val_acc: 0.9091\n",
      "Epoch 486/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23021.9312 - acc: 0.9615 - val_loss: 521669.2580 - val_acc: 0.9163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 23081.8156 - acc: 0.9620 - val_loss: 482336.2163 - val_acc: 0.9107\n",
      "Epoch 488/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22971.1249 - acc: 0.9608 - val_loss: 495533.6459 - val_acc: 0.9130\n",
      "Epoch 489/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23566.1797 - acc: 0.9598 - val_loss: 482769.2945 - val_acc: 0.9082\n",
      "Epoch 490/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22933.0013 - acc: 0.9625 - val_loss: 487595.0483 - val_acc: 0.9136\n",
      "Epoch 491/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 23069.7198 - acc: 0.9622 - val_loss: 482114.7116 - val_acc: 0.9146\n",
      "Epoch 492/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22931.5668 - acc: 0.9619 - val_loss: 491926.7128 - val_acc: 0.9138\n",
      "Epoch 493/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23031.9436 - acc: 0.9621 - val_loss: 469231.2007 - val_acc: 0.9112\n",
      "Epoch 494/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22954.6900 - acc: 0.9621 - val_loss: 496726.2114 - val_acc: 0.9111\n",
      "Epoch 495/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23316.6807 - acc: 0.9602 - val_loss: 496852.3729 - val_acc: 0.9049\n",
      "Epoch 496/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22945.9307 - acc: 0.9622 - val_loss: 509471.1003 - val_acc: 0.9122\n",
      "Epoch 497/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22903.4466 - acc: 0.9616 - val_loss: 468082.9979 - val_acc: 0.9080\n",
      "Epoch 498/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22521.8521 - acc: 0.9628 - val_loss: 490819.8548 - val_acc: 0.9140\n",
      "Epoch 499/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22815.7760 - acc: 0.9621 - val_loss: 473255.6242 - val_acc: 0.9141\n",
      "Epoch 500/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23278.7790 - acc: 0.9625 - val_loss: 516790.4322 - val_acc: 0.9087\n",
      "Epoch 501/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22761.8383 - acc: 0.9621 - val_loss: 495000.3810 - val_acc: 0.9181\n",
      "Epoch 502/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22427.5942 - acc: 0.9627 - val_loss: 493141.8393 - val_acc: 0.9107\n",
      "Epoch 503/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 23465.1781 - acc: 0.9617 - val_loss: 534687.4234 - val_acc: 0.9180\n",
      "Epoch 504/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22544.9332 - acc: 0.9621 - val_loss: 502398.6464 - val_acc: 0.9203\n",
      "Epoch 505/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22433.0685 - acc: 0.9623 - val_loss: 513991.2920 - val_acc: 0.9136\n",
      "Epoch 506/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22701.3106 - acc: 0.9620 - val_loss: 514003.6274 - val_acc: 0.9169\n",
      "Epoch 507/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22523.6465 - acc: 0.9618 - val_loss: 518400.3850 - val_acc: 0.9146\n",
      "Epoch 508/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22725.3626 - acc: 0.9618 - val_loss: 501110.8548 - val_acc: 0.9159\n",
      "Epoch 509/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22829.7668 - acc: 0.9617 - val_loss: 499236.8994 - val_acc: 0.9129\n",
      "Epoch 510/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22436.2658 - acc: 0.9630 - val_loss: 514536.4737 - val_acc: 0.9116\n",
      "Epoch 511/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22461.3568 - acc: 0.9620 - val_loss: 512141.7284 - val_acc: 0.9162\n",
      "Epoch 512/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22783.3586 - acc: 0.9623 - val_loss: 484635.1167 - val_acc: 0.9104\n",
      "Epoch 513/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22397.8673 - acc: 0.9623 - val_loss: 530554.0628 - val_acc: 0.9106\n",
      "Epoch 514/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22601.2012 - acc: 0.9623 - val_loss: 515488.5830 - val_acc: 0.9119\n",
      "Epoch 515/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22336.0245 - acc: 0.9622 - val_loss: 510141.0286 - val_acc: 0.9087\n",
      "Epoch 516/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 23166.5696 - acc: 0.9615 - val_loss: 518448.1482 - val_acc: 0.9098\n",
      "Epoch 517/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22605.0204 - acc: 0.9626 - val_loss: 519243.0966 - val_acc: 0.9173\n",
      "Epoch 518/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22510.3486 - acc: 0.9631 - val_loss: 514723.6022 - val_acc: 0.9072\n",
      "Epoch 519/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22658.1112 - acc: 0.9622 - val_loss: 513962.2261 - val_acc: 0.9134\n",
      "Epoch 520/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22436.2110 - acc: 0.9618 - val_loss: 507786.8688 - val_acc: 0.9128\n",
      "Epoch 521/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 22828.4701 - acc: 0.9619 - val_loss: 497421.9127 - val_acc: 0.9135\n",
      "Epoch 522/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22093.6224 - acc: 0.9620 - val_loss: 517803.2092 - val_acc: 0.9080\n",
      "Epoch 523/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22320.5815 - acc: 0.9624 - val_loss: 505093.7928 - val_acc: 0.9158\n",
      "Epoch 524/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22498.3630 - acc: 0.9632 - val_loss: 534969.9183 - val_acc: 0.9091\n",
      "Epoch 525/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22661.9319 - acc: 0.9639 - val_loss: 497920.8168 - val_acc: 0.9181\n",
      "Epoch 526/1000\n",
      "63424/63424 [==============================] - 3s 43us/sample - loss: 22309.0878 - acc: 0.9632 - val_loss: 516932.5378 - val_acc: 0.9061\n",
      "Epoch 527/1000\n",
      "63424/63424 [==============================] - 3s 44us/sample - loss: 22443.6192 - acc: 0.9627 - val_loss: 499808.0172 - val_acc: 0.9134\n",
      "Epoch 528/1000\n",
      "63424/63424 [==============================] - 3s 43us/sample - loss: 22382.8458 - acc: 0.9626 - val_loss: 526397.2173 - val_acc: 0.9137\n",
      "Epoch 529/1000\n",
      "63424/63424 [==============================] - 3s 44us/sample - loss: 22499.0400 - acc: 0.9623 - val_loss: 538965.5105 - val_acc: 0.9149\n",
      "Epoch 530/1000\n",
      "63424/63424 [==============================] - 3s 44us/sample - loss: 22244.4410 - acc: 0.9619 - val_loss: 534436.7924 - val_acc: 0.9105\n",
      "Epoch 531/1000\n",
      "63424/63424 [==============================] - 3s 44us/sample - loss: 22254.0849 - acc: 0.9621 - val_loss: 506066.7231 - val_acc: 0.9091\n",
      "Epoch 532/1000\n",
      "63424/63424 [==============================] - 3s 44us/sample - loss: 22262.6843 - acc: 0.9624 - val_loss: 511742.9074 - val_acc: 0.9139\n",
      "Epoch 533/1000\n",
      "63424/63424 [==============================] - 3s 44us/sample - loss: 22082.4886 - acc: 0.9613 - val_loss: 487660.9751 - val_acc: 0.9125\n",
      "Epoch 534/1000\n",
      "63424/63424 [==============================] - 3s 43us/sample - loss: 22121.0602 - acc: 0.9611 - val_loss: 515092.6979 - val_acc: 0.9083\n",
      "Epoch 535/1000\n",
      "63424/63424 [==============================] - 3s 44us/sample - loss: 22606.2626 - acc: 0.9617 - val_loss: 509411.2877 - val_acc: 0.9132\n",
      "Epoch 536/1000\n",
      "63424/63424 [==============================] - 3s 43us/sample - loss: 22173.0565 - acc: 0.9618 - val_loss: 505041.9649 - val_acc: 0.9161\n",
      "Epoch 537/1000\n",
      "63424/63424 [==============================] - 3s 43us/sample - loss: 22038.8134 - acc: 0.9624 - val_loss: 506941.3247 - val_acc: 0.9157\n",
      "Epoch 538/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22067.7778 - acc: 0.9629 - val_loss: 503005.0895 - val_acc: 0.9147\n",
      "Epoch 539/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22049.4223 - acc: 0.9629 - val_loss: 518387.7083 - val_acc: 0.9172\n",
      "Epoch 540/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 22071.5373 - acc: 0.9632 - val_loss: 496812.6676 - val_acc: 0.9139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 22438.6227 - acc: 0.9617 - val_loss: 526519.9902 - val_acc: 0.9104\n",
      "Epoch 542/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22111.1373 - acc: 0.9626 - val_loss: 505705.1471 - val_acc: 0.9152\n",
      "Epoch 543/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22292.0230 - acc: 0.9627 - val_loss: 529973.7161 - val_acc: 0.9159\n",
      "Epoch 544/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21702.2628 - acc: 0.9635 - val_loss: 507386.4120 - val_acc: 0.9180\n",
      "Epoch 545/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22027.1316 - acc: 0.9628 - val_loss: 522479.3939 - val_acc: 0.9164\n",
      "Epoch 546/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22337.2294 - acc: 0.9629 - val_loss: 520535.9289 - val_acc: 0.9155\n",
      "Epoch 547/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 22218.5275 - acc: 0.9624 - val_loss: 545888.5390 - val_acc: 0.8997\n",
      "Epoch 548/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 22522.3989 - acc: 0.9629 - val_loss: 515701.7045 - val_acc: 0.9084\n",
      "Epoch 549/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21989.7935 - acc: 0.9623 - val_loss: 516441.2051 - val_acc: 0.9144\n",
      "Epoch 550/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22139.5598 - acc: 0.9616 - val_loss: 515379.4056 - val_acc: 0.9174\n",
      "Epoch 551/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21950.1500 - acc: 0.9633 - val_loss: 517251.7183 - val_acc: 0.9160\n",
      "Epoch 552/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22018.9336 - acc: 0.9613 - val_loss: 519246.1503 - val_acc: 0.9115\n",
      "Epoch 553/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22260.7550 - acc: 0.9623 - val_loss: 475494.6239 - val_acc: 0.9102\n",
      "Epoch 554/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21877.9809 - acc: 0.9633 - val_loss: 518092.3302 - val_acc: 0.9105\n",
      "Epoch 555/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21690.9153 - acc: 0.9627 - val_loss: 486626.4382 - val_acc: 0.9119\n",
      "Epoch 556/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21976.8052 - acc: 0.9627 - val_loss: 514133.5952 - val_acc: 0.9129\n",
      "Epoch 557/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21859.2809 - acc: 0.9629 - val_loss: 509498.9145 - val_acc: 0.9171\n",
      "Epoch 558/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22089.8202 - acc: 0.9627 - val_loss: 511201.1673 - val_acc: 0.9118\n",
      "Epoch 559/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21560.8423 - acc: 0.9627 - val_loss: 504098.4938 - val_acc: 0.9137\n",
      "Epoch 560/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21694.1737 - acc: 0.9642 - val_loss: 523477.4503 - val_acc: 0.9090\n",
      "Epoch 561/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21889.6086 - acc: 0.9620 - val_loss: 521746.4707 - val_acc: 0.9152\n",
      "Epoch 562/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 22056.9233 - acc: 0.9632 - val_loss: 490493.1234 - val_acc: 0.9093\n",
      "Epoch 563/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21613.7313 - acc: 0.9632 - val_loss: 518234.9751 - val_acc: 0.9108\n",
      "Epoch 564/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21808.9095 - acc: 0.9627 - val_loss: 517966.4166 - val_acc: 0.9152\n",
      "Epoch 565/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21833.5977 - acc: 0.9622 - val_loss: 508235.5975 - val_acc: 0.9044\n",
      "Epoch 566/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21485.2547 - acc: 0.9641 - val_loss: 495395.3728 - val_acc: 0.9155\n",
      "Epoch 567/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21767.5921 - acc: 0.9629 - val_loss: 493323.6207 - val_acc: 0.9113\n",
      "Epoch 568/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21735.2851 - acc: 0.9637 - val_loss: 534884.8569 - val_acc: 0.9061\n",
      "Epoch 569/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 22054.7867 - acc: 0.9628 - val_loss: 502573.6921 - val_acc: 0.9130\n",
      "Epoch 570/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21690.4124 - acc: 0.9634 - val_loss: 518226.3606 - val_acc: 0.9169\n",
      "Epoch 571/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21341.5039 - acc: 0.9635 - val_loss: 538872.4859 - val_acc: 0.9142\n",
      "Epoch 572/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21675.7622 - acc: 0.9635 - val_loss: 531697.6071 - val_acc: 0.9153\n",
      "Epoch 573/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21582.2701 - acc: 0.9637 - val_loss: 521197.8194 - val_acc: 0.9126\n",
      "Epoch 574/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21657.9258 - acc: 0.9632 - val_loss: 505607.2663 - val_acc: 0.9146\n",
      "Epoch 575/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21529.5637 - acc: 0.9642 - val_loss: 518203.3978 - val_acc: 0.9115\n",
      "Epoch 576/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21287.1089 - acc: 0.9634 - val_loss: 520978.6243 - val_acc: 0.9151\n",
      "Epoch 577/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21521.2507 - acc: 0.9627 - val_loss: 519817.9368 - val_acc: 0.9076\n",
      "Epoch 578/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21502.8458 - acc: 0.9629 - val_loss: 530994.3509 - val_acc: 0.9170\n",
      "Epoch 579/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21408.3392 - acc: 0.9635 - val_loss: 532732.7893 - val_acc: 0.9158\n",
      "Epoch 580/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21497.0594 - acc: 0.9629 - val_loss: 531581.6379 - val_acc: 0.9120\n",
      "Epoch 581/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21528.3848 - acc: 0.9627 - val_loss: 517169.8288 - val_acc: 0.9126\n",
      "Epoch 582/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21491.5708 - acc: 0.9637 - val_loss: 524530.8026 - val_acc: 0.9126\n",
      "Epoch 583/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21505.1567 - acc: 0.9630 - val_loss: 522618.0083 - val_acc: 0.9046\n",
      "Epoch 584/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21690.0367 - acc: 0.9621 - val_loss: 522711.2720 - val_acc: 0.9114\n",
      "Epoch 585/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21710.5749 - acc: 0.9635 - val_loss: 520574.7476 - val_acc: 0.9159\n",
      "Epoch 586/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21424.2193 - acc: 0.9635 - val_loss: 516213.1613 - val_acc: 0.9120\n",
      "Epoch 587/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21618.7324 - acc: 0.9636 - val_loss: 553904.7804 - val_acc: 0.9114\n",
      "Epoch 588/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21459.9262 - acc: 0.9638 - val_loss: 535593.8764 - val_acc: 0.9160\n",
      "Epoch 589/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21737.8889 - acc: 0.9628 - val_loss: 508504.5666 - val_acc: 0.9112\n",
      "Epoch 590/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21503.2342 - acc: 0.9633 - val_loss: 497690.4995 - val_acc: 0.9136\n",
      "Epoch 591/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21466.5658 - acc: 0.9635 - val_loss: 531858.9565 - val_acc: 0.9128\n",
      "Epoch 592/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21141.3447 - acc: 0.9629 - val_loss: 509954.6473 - val_acc: 0.9131\n",
      "Epoch 593/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21496.0275 - acc: 0.9627 - val_loss: 527708.4590 - val_acc: 0.9088\n",
      "Epoch 594/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20929.0747 - acc: 0.9636 - val_loss: 498098.3356 - val_acc: 0.9159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 595/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21767.6491 - acc: 0.9629 - val_loss: 536322.1562 - val_acc: 0.9027\n",
      "Epoch 596/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21060.6849 - acc: 0.9635 - val_loss: 546617.6383 - val_acc: 0.9062\n",
      "Epoch 597/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21505.8212 - acc: 0.9638 - val_loss: 510652.1811 - val_acc: 0.9154\n",
      "Epoch 598/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21300.5658 - acc: 0.9634 - val_loss: 527039.0186 - val_acc: 0.9135\n",
      "Epoch 599/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21292.7633 - acc: 0.9633 - val_loss: 536154.6799 - val_acc: 0.9167\n",
      "Epoch 600/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21145.4238 - acc: 0.9629 - val_loss: 520370.2240 - val_acc: 0.9072\n",
      "Epoch 601/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21263.5148 - acc: 0.9643 - val_loss: 500561.0770 - val_acc: 0.9092\n",
      "Epoch 602/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20951.0598 - acc: 0.9643 - val_loss: 527408.8757 - val_acc: 0.9105\n",
      "Epoch 603/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21519.2536 - acc: 0.9633 - val_loss: 517804.9872 - val_acc: 0.9132\n",
      "Epoch 604/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21433.7072 - acc: 0.9637 - val_loss: 527680.5885 - val_acc: 0.9148\n",
      "Epoch 605/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21064.0768 - acc: 0.9644 - val_loss: 536335.9544 - val_acc: 0.9106\n",
      "Epoch 606/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21464.4667 - acc: 0.9627 - val_loss: 540661.0117 - val_acc: 0.9102\n",
      "Epoch 607/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21814.1687 - acc: 0.9635 - val_loss: 527094.6142 - val_acc: 0.9008\n",
      "Epoch 608/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20733.6040 - acc: 0.9638 - val_loss: 520056.1580 - val_acc: 0.9081\n",
      "Epoch 609/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21099.8293 - acc: 0.9633 - val_loss: 495518.0154 - val_acc: 0.9112\n",
      "Epoch 610/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21155.0804 - acc: 0.9637 - val_loss: 519323.8840 - val_acc: 0.9175\n",
      "Epoch 611/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21342.2077 - acc: 0.9631 - val_loss: 512087.8803 - val_acc: 0.9130\n",
      "Epoch 612/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21309.6179 - acc: 0.9642 - val_loss: 532397.1614 - val_acc: 0.9110\n",
      "Epoch 613/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 20913.4504 - acc: 0.9642 - val_loss: 538399.1433 - val_acc: 0.9098\n",
      "Epoch 614/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21345.5138 - acc: 0.9640 - val_loss: 504298.8042 - val_acc: 0.9176\n",
      "Epoch 615/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21129.6767 - acc: 0.9634 - val_loss: 558302.0920 - val_acc: 0.9146\n",
      "Epoch 616/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21084.4364 - acc: 0.9638 - val_loss: 519028.9670 - val_acc: 0.9124\n",
      "Epoch 617/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20912.6278 - acc: 0.9646 - val_loss: 537901.0002 - val_acc: 0.9118\n",
      "Epoch 618/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21326.1497 - acc: 0.9621 - val_loss: 519400.5455 - val_acc: 0.9168\n",
      "Epoch 619/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21196.2844 - acc: 0.9639 - val_loss: 531275.2939 - val_acc: 0.9094\n",
      "Epoch 620/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 20842.8653 - acc: 0.9643 - val_loss: 533758.1894 - val_acc: 0.9149\n",
      "Epoch 621/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 20963.7387 - acc: 0.9641 - val_loss: 529378.4117 - val_acc: 0.9167\n",
      "Epoch 622/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20937.5681 - acc: 0.9635 - val_loss: 529226.2281 - val_acc: 0.9167\n",
      "Epoch 623/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20995.6559 - acc: 0.9639 - val_loss: 516468.7643 - val_acc: 0.9183\n",
      "Epoch 624/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21024.0825 - acc: 0.9641 - val_loss: 515465.2729 - val_acc: 0.9129\n",
      "Epoch 625/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20977.9054 - acc: 0.9631 - val_loss: 535621.8988 - val_acc: 0.9024\n",
      "Epoch 626/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20799.9461 - acc: 0.9646 - val_loss: 549617.3973 - val_acc: 0.9115\n",
      "Epoch 627/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21165.4174 - acc: 0.9633 - val_loss: 550084.6429 - val_acc: 0.9189\n",
      "Epoch 628/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21099.5106 - acc: 0.9637 - val_loss: 498786.8430 - val_acc: 0.9088\n",
      "Epoch 629/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20723.9531 - acc: 0.9633 - val_loss: 524303.7994 - val_acc: 0.9150\n",
      "Epoch 630/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20889.9029 - acc: 0.9638 - val_loss: 562624.2477 - val_acc: 0.9193\n",
      "Epoch 631/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21040.0797 - acc: 0.9635 - val_loss: 556545.4780 - val_acc: 0.9004\n",
      "Epoch 632/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20703.6513 - acc: 0.9647 - val_loss: 523050.7606 - val_acc: 0.9098\n",
      "Epoch 633/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21005.8272 - acc: 0.9645 - val_loss: 523327.7100 - val_acc: 0.9166\n",
      "Epoch 634/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20392.1401 - acc: 0.9638 - val_loss: 520584.6448 - val_acc: 0.9148\n",
      "Epoch 635/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21274.6648 - acc: 0.9629 - val_loss: 529647.7704 - val_acc: 0.9199\n",
      "Epoch 636/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20472.8939 - acc: 0.9644 - val_loss: 524107.7588 - val_acc: 0.9086\n",
      "Epoch 637/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 21309.5330 - acc: 0.9643 - val_loss: 508368.4034 - val_acc: 0.9159\n",
      "Epoch 638/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20851.7811 - acc: 0.9644 - val_loss: 533697.9887 - val_acc: 0.9038\n",
      "Epoch 639/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20548.8796 - acc: 0.9647 - val_loss: 523469.8011 - val_acc: 0.9179\n",
      "Epoch 640/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20842.2689 - acc: 0.9652 - val_loss: 540581.5580 - val_acc: 0.9083\n",
      "Epoch 641/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20805.1985 - acc: 0.9640 - val_loss: 526038.6102 - val_acc: 0.9071\n",
      "Epoch 642/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20708.4386 - acc: 0.9643 - val_loss: 513886.2600 - val_acc: 0.9148\n",
      "Epoch 643/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21067.8836 - acc: 0.9637 - val_loss: 541074.8174 - val_acc: 0.9136\n",
      "Epoch 644/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20331.9733 - acc: 0.9648 - val_loss: 511231.3024 - val_acc: 0.9108\n",
      "Epoch 645/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 21054.6450 - acc: 0.9644 - val_loss: 519870.9386 - val_acc: 0.8994\n",
      "Epoch 646/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20716.0315 - acc: 0.9635 - val_loss: 529513.3479 - val_acc: 0.9163\n",
      "Epoch 647/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20503.6130 - acc: 0.9638 - val_loss: 529988.7954 - val_acc: 0.9089\n",
      "Epoch 648/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20815.4924 - acc: 0.9633 - val_loss: 536454.3233 - val_acc: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 649/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20591.7186 - acc: 0.9644 - val_loss: 513071.5529 - val_acc: 0.9116\n",
      "Epoch 650/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20770.2477 - acc: 0.9627 - val_loss: 530764.2150 - val_acc: 0.9039\n",
      "Epoch 651/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 20774.1267 - acc: 0.9642 - val_loss: 521803.8743 - val_acc: 0.9103\n",
      "Epoch 652/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 21030.5351 - acc: 0.9642 - val_loss: 568206.7204 - val_acc: 0.9158\n",
      "Epoch 653/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 20524.3750 - acc: 0.9645 - val_loss: 529289.2099 - val_acc: 0.9124\n",
      "Epoch 654/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20834.4938 - acc: 0.9636 - val_loss: 538869.5506 - val_acc: 0.9142\n",
      "Epoch 655/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20551.1236 - acc: 0.9645 - val_loss: 523182.0017 - val_acc: 0.9099\n",
      "Epoch 656/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20312.6413 - acc: 0.9649 - val_loss: 556776.1274 - val_acc: 0.9164\n",
      "Epoch 657/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20822.3310 - acc: 0.9644 - val_loss: 550225.0955 - val_acc: 0.9132\n",
      "Epoch 658/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20555.5726 - acc: 0.9638 - val_loss: 545309.1943 - val_acc: 0.9143\n",
      "Epoch 659/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20559.4107 - acc: 0.9651 - val_loss: 557344.0412 - val_acc: 0.9103\n",
      "Epoch 660/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20609.3774 - acc: 0.9637 - val_loss: 558374.2629 - val_acc: 0.9143\n",
      "Epoch 661/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20676.3730 - acc: 0.9642 - val_loss: 533959.5995 - val_acc: 0.9150\n",
      "Epoch 662/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20381.9243 - acc: 0.9646 - val_loss: 536556.2306 - val_acc: 0.9137\n",
      "Epoch 663/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20370.8978 - acc: 0.9651 - val_loss: 555023.4282 - val_acc: 0.9079\n",
      "Epoch 664/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20826.2692 - acc: 0.9639 - val_loss: 543270.8526 - val_acc: 0.9072\n",
      "Epoch 665/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20350.9481 - acc: 0.9649 - val_loss: 534807.5836 - val_acc: 0.9058\n",
      "Epoch 666/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20222.9040 - acc: 0.9653 - val_loss: 541716.2951 - val_acc: 0.9107\n",
      "Epoch 667/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20571.7984 - acc: 0.9643 - val_loss: 525115.1837 - val_acc: 0.9127\n",
      "Epoch 668/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20437.0906 - acc: 0.9638 - val_loss: 552655.2973 - val_acc: 0.9166\n",
      "Epoch 669/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20560.5843 - acc: 0.9641 - val_loss: 531594.6915 - val_acc: 0.9099\n",
      "Epoch 670/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20459.2551 - acc: 0.9648 - val_loss: 563186.7511 - val_acc: 0.9120\n",
      "Epoch 671/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20672.0455 - acc: 0.9640 - val_loss: 547918.3192 - val_acc: 0.9119\n",
      "Epoch 672/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20199.2985 - acc: 0.9647 - val_loss: 524368.6461 - val_acc: 0.9141\n",
      "Epoch 673/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20473.7388 - acc: 0.9650 - val_loss: 540852.8397 - val_acc: 0.9113\n",
      "Epoch 674/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20628.7511 - acc: 0.9645 - val_loss: 554281.2460 - val_acc: 0.9140\n",
      "Epoch 675/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20332.7543 - acc: 0.9638 - val_loss: 530841.1310 - val_acc: 0.9079\n",
      "Epoch 676/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20310.5824 - acc: 0.9648 - val_loss: 533176.7532 - val_acc: 0.9082\n",
      "Epoch 677/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20562.2548 - acc: 0.9639 - val_loss: 560305.5247 - val_acc: 0.9117\n",
      "Epoch 678/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20326.5366 - acc: 0.9647 - val_loss: 536069.9752 - val_acc: 0.9135\n",
      "Epoch 679/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20692.3298 - acc: 0.9641 - val_loss: 557110.0495 - val_acc: 0.9165\n",
      "Epoch 680/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20452.7531 - acc: 0.9651 - val_loss: 533407.6569 - val_acc: 0.9176\n",
      "Epoch 681/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20132.2011 - acc: 0.9649 - val_loss: 559755.0862 - val_acc: 0.9119\n",
      "Epoch 682/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20428.7131 - acc: 0.9657 - val_loss: 575659.4439 - val_acc: 0.9162\n",
      "Epoch 683/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20065.4919 - acc: 0.9640 - val_loss: 544958.6341 - val_acc: 0.9072\n",
      "Epoch 684/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20451.2441 - acc: 0.9644 - val_loss: 562922.9422 - val_acc: 0.9100\n",
      "Epoch 685/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20071.4165 - acc: 0.9653 - val_loss: 567111.0808 - val_acc: 0.9086\n",
      "Epoch 686/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20494.9518 - acc: 0.9632 - val_loss: 539194.4195 - val_acc: 0.9082\n",
      "Epoch 687/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20269.4789 - acc: 0.9640 - val_loss: 542782.1323 - val_acc: 0.9133\n",
      "Epoch 688/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20305.1867 - acc: 0.9647 - val_loss: 558505.4520 - val_acc: 0.9167\n",
      "Epoch 689/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20453.6332 - acc: 0.9645 - val_loss: 527871.8982 - val_acc: 0.9120\n",
      "Epoch 690/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20599.1807 - acc: 0.9646 - val_loss: 563149.7641 - val_acc: 0.9107\n",
      "Epoch 691/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20299.1588 - acc: 0.9653 - val_loss: 553248.0608 - val_acc: 0.9107\n",
      "Epoch 692/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20226.5627 - acc: 0.9636 - val_loss: 548428.0791 - val_acc: 0.9145\n",
      "Epoch 693/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20054.4560 - acc: 0.9644 - val_loss: 557130.9108 - val_acc: 0.9171\n",
      "Epoch 694/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20166.8907 - acc: 0.9655 - val_loss: 571419.8006 - val_acc: 0.9143\n",
      "Epoch 695/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20523.8453 - acc: 0.9646 - val_loss: 530627.3799 - val_acc: 0.9136\n",
      "Epoch 696/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19524.8136 - acc: 0.9644 - val_loss: 561845.9940 - val_acc: 0.9174\n",
      "Epoch 697/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20306.7670 - acc: 0.9639 - val_loss: 542035.3811 - val_acc: 0.9136\n",
      "Epoch 698/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19910.0584 - acc: 0.9645 - val_loss: 533251.7446 - val_acc: 0.9109\n",
      "Epoch 699/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20320.6527 - acc: 0.9638 - val_loss: 559911.5344 - val_acc: 0.9151\n",
      "Epoch 700/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20321.1978 - acc: 0.9648 - val_loss: 546410.4385 - val_acc: 0.9058\n",
      "Epoch 701/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20269.3380 - acc: 0.9639 - val_loss: 595586.7715 - val_acc: 0.9155\n",
      "Epoch 702/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20147.6905 - acc: 0.9649 - val_loss: 560364.9396 - val_acc: 0.9087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 703/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19994.5172 - acc: 0.9641 - val_loss: 542398.1131 - val_acc: 0.9155\n",
      "Epoch 704/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19907.8797 - acc: 0.9658 - val_loss: 583659.4914 - val_acc: 0.9016\n",
      "Epoch 705/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 20138.8047 - acc: 0.9653 - val_loss: 586970.0165 - val_acc: 0.9160\n",
      "Epoch 706/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20230.5120 - acc: 0.9658 - val_loss: 540465.6201 - val_acc: 0.9142\n",
      "Epoch 707/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20076.2958 - acc: 0.9650 - val_loss: 559495.6226 - val_acc: 0.9082\n",
      "Epoch 708/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19980.8397 - acc: 0.9651 - val_loss: 530330.1589 - val_acc: 0.9136\n",
      "Epoch 709/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19905.1240 - acc: 0.9653 - val_loss: 582799.5060 - val_acc: 0.9094\n",
      "Epoch 710/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19959.5729 - acc: 0.9649 - val_loss: 549073.2640 - val_acc: 0.9128\n",
      "Epoch 711/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19987.0530 - acc: 0.9647 - val_loss: 574257.2712 - val_acc: 0.9080\n",
      "Epoch 712/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20091.2475 - acc: 0.9652 - val_loss: 554517.9209 - val_acc: 0.9121\n",
      "Epoch 713/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20027.0244 - acc: 0.9640 - val_loss: 553926.3087 - val_acc: 0.9095\n",
      "Epoch 714/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20080.3819 - acc: 0.9653 - val_loss: 548342.5860 - val_acc: 0.9131\n",
      "Epoch 715/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 19699.6041 - acc: 0.9640 - val_loss: 554837.0087 - val_acc: 0.9151\n",
      "Epoch 716/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20121.0735 - acc: 0.9645 - val_loss: 546939.6528 - val_acc: 0.9125\n",
      "Epoch 717/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19804.3471 - acc: 0.9652 - val_loss: 543769.5719 - val_acc: 0.9047\n",
      "Epoch 718/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20125.3792 - acc: 0.9644 - val_loss: 584307.6903 - val_acc: 0.9186\n",
      "Epoch 719/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20171.0840 - acc: 0.9647 - val_loss: 536238.9737 - val_acc: 0.9061\n",
      "Epoch 720/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19654.5643 - acc: 0.9652 - val_loss: 556914.3894 - val_acc: 0.9154\n",
      "Epoch 721/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19767.5025 - acc: 0.9639 - val_loss: 583762.4908 - val_acc: 0.9161\n",
      "Epoch 722/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19728.4514 - acc: 0.9648 - val_loss: 538279.5593 - val_acc: 0.9111\n",
      "Epoch 723/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20340.6624 - acc: 0.9644 - val_loss: 562333.4402 - val_acc: 0.9061\n",
      "Epoch 724/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 19602.3369 - acc: 0.9657 - val_loss: 556086.2504 - val_acc: 0.9147\n",
      "Epoch 725/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20036.5084 - acc: 0.9650 - val_loss: 544136.8632 - val_acc: 0.9168\n",
      "Epoch 726/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 19775.4973 - acc: 0.9655 - val_loss: 566219.0453 - val_acc: 0.9142\n",
      "Epoch 727/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19541.2040 - acc: 0.9647 - val_loss: 539525.1754 - val_acc: 0.9124\n",
      "Epoch 728/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20170.3157 - acc: 0.9656 - val_loss: 573422.0189 - val_acc: 0.9144\n",
      "Epoch 729/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19558.1684 - acc: 0.9652 - val_loss: 578436.4170 - val_acc: 0.9054\n",
      "Epoch 730/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19726.8562 - acc: 0.9644 - val_loss: 549527.5075 - val_acc: 0.9139\n",
      "Epoch 731/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19690.2972 - acc: 0.9648 - val_loss: 551771.5380 - val_acc: 0.9146\n",
      "Epoch 732/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19615.8554 - acc: 0.9654 - val_loss: 559487.0487 - val_acc: 0.9075\n",
      "Epoch 733/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 20175.6120 - acc: 0.9639 - val_loss: 586642.9060 - val_acc: 0.9041\n",
      "Epoch 734/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19768.5302 - acc: 0.9650 - val_loss: 557955.1003 - val_acc: 0.9133\n",
      "Epoch 735/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 20191.6692 - acc: 0.9637 - val_loss: 561347.9809 - val_acc: 0.9123\n",
      "Epoch 736/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19616.5226 - acc: 0.9662 - val_loss: 559674.3227 - val_acc: 0.9106\n",
      "Epoch 737/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19933.8320 - acc: 0.9646 - val_loss: 565382.0681 - val_acc: 0.9126\n",
      "Epoch 738/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19689.3622 - acc: 0.9664 - val_loss: 548150.9004 - val_acc: 0.9150\n",
      "Epoch 739/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19802.4816 - acc: 0.9646 - val_loss: 562594.6582 - val_acc: 0.9181\n",
      "Epoch 740/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19382.4056 - acc: 0.9652 - val_loss: 532540.6253 - val_acc: 0.9155\n",
      "Epoch 741/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19953.8951 - acc: 0.9656 - val_loss: 556961.5035 - val_acc: 0.9125\n",
      "Epoch 742/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19585.1400 - acc: 0.9643 - val_loss: 574565.1257 - val_acc: 0.9104\n",
      "Epoch 743/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19477.6018 - acc: 0.9657 - val_loss: 581861.5345 - val_acc: 0.9089\n",
      "Epoch 744/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19667.4867 - acc: 0.9644 - val_loss: 576671.3214 - val_acc: 0.9102\n",
      "Epoch 745/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19519.8789 - acc: 0.9653 - val_loss: 563667.6555 - val_acc: 0.9133\n",
      "Epoch 746/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19526.4648 - acc: 0.9645 - val_loss: 567981.3514 - val_acc: 0.9129\n",
      "Epoch 747/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19886.2168 - acc: 0.9655 - val_loss: 554906.5370 - val_acc: 0.9083\n",
      "Epoch 748/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19550.2349 - acc: 0.9660 - val_loss: 546516.3746 - val_acc: 0.9127\n",
      "Epoch 749/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19676.0624 - acc: 0.9653 - val_loss: 534483.0441 - val_acc: 0.9089\n",
      "Epoch 750/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19734.5801 - acc: 0.9647 - val_loss: 573829.5072 - val_acc: 0.9125\n",
      "Epoch 751/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19856.0139 - acc: 0.9646 - val_loss: 556984.5988 - val_acc: 0.9123\n",
      "Epoch 752/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19387.2864 - acc: 0.9662 - val_loss: 566104.1464 - val_acc: 0.9126\n",
      "Epoch 753/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19390.9890 - acc: 0.9647 - val_loss: 575895.7851 - val_acc: 0.9132\n",
      "Epoch 754/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19353.9316 - acc: 0.9652 - val_loss: 556069.4390 - val_acc: 0.9194\n",
      "Epoch 755/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19731.5381 - acc: 0.9651 - val_loss: 555232.4200 - val_acc: 0.9162\n",
      "Epoch 756/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19556.9041 - acc: 0.9655 - val_loss: 580817.9469 - val_acc: 0.9095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19456.0880 - acc: 0.9657 - val_loss: 570451.4449 - val_acc: 0.9151\n",
      "Epoch 758/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19797.9916 - acc: 0.9651 - val_loss: 550974.1105 - val_acc: 0.9139\n",
      "Epoch 759/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19386.9358 - acc: 0.9649 - val_loss: 570460.2615 - val_acc: 0.9157\n",
      "Epoch 760/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19706.7102 - acc: 0.9647 - val_loss: 583260.8956 - val_acc: 0.9140\n",
      "Epoch 761/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 19711.2776 - acc: 0.9654 - val_loss: 541917.0056 - val_acc: 0.9125\n",
      "Epoch 762/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19701.4623 - acc: 0.9652 - val_loss: 533225.2608 - val_acc: 0.9105\n",
      "Epoch 763/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19443.7779 - acc: 0.9650 - val_loss: 587632.0070 - val_acc: 0.9137\n",
      "Epoch 764/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19856.7670 - acc: 0.9655 - val_loss: 555588.4826 - val_acc: 0.9146\n",
      "Epoch 765/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19352.6086 - acc: 0.9648 - val_loss: 579849.0057 - val_acc: 0.9086\n",
      "Epoch 766/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19314.3365 - acc: 0.9649 - val_loss: 583235.2272 - val_acc: 0.9072\n",
      "Epoch 767/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19422.3065 - acc: 0.9655 - val_loss: 561972.2581 - val_acc: 0.9086\n",
      "Epoch 768/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19770.4918 - acc: 0.9656 - val_loss: 549594.9270 - val_acc: 0.9067\n",
      "Epoch 769/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19422.6643 - acc: 0.9652 - val_loss: 564106.5272 - val_acc: 0.9072\n",
      "Epoch 770/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19759.2443 - acc: 0.9657 - val_loss: 575640.9991 - val_acc: 0.9120\n",
      "Epoch 771/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 19382.9302 - acc: 0.9653 - val_loss: 599812.7959 - val_acc: 0.9173\n",
      "Epoch 772/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19571.2124 - acc: 0.9650 - val_loss: 554450.5355 - val_acc: 0.9107\n",
      "Epoch 773/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 19451.4025 - acc: 0.9658 - val_loss: 563456.5794 - val_acc: 0.9089\n",
      "Epoch 774/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 19773.2620 - acc: 0.9644 - val_loss: 547998.0012 - val_acc: 0.9131\n",
      "Epoch 775/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19592.4782 - acc: 0.9655 - val_loss: 621615.4205 - val_acc: 0.9096\n",
      "Epoch 776/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 19518.3025 - acc: 0.9664 - val_loss: 594554.7687 - val_acc: 0.9098\n",
      "Epoch 777/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19416.0466 - acc: 0.9652 - val_loss: 570155.5781 - val_acc: 0.9077\n",
      "Epoch 778/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19060.2593 - acc: 0.9662 - val_loss: 539651.6020 - val_acc: 0.9101\n",
      "Epoch 779/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19593.3891 - acc: 0.9652 - val_loss: 590166.1470 - val_acc: 0.9125\n",
      "Epoch 780/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19658.9695 - acc: 0.9645 - val_loss: 563381.5620 - val_acc: 0.9101\n",
      "Epoch 781/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18876.7460 - acc: 0.9663 - val_loss: 547909.7200 - val_acc: 0.9104\n",
      "Epoch 782/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18968.5879 - acc: 0.9651 - val_loss: 561226.5972 - val_acc: 0.9085\n",
      "Epoch 783/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19707.3666 - acc: 0.9651 - val_loss: 575446.5879 - val_acc: 0.9112\n",
      "Epoch 784/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19380.3554 - acc: 0.9655 - val_loss: 555286.5165 - val_acc: 0.9057\n",
      "Epoch 785/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19330.4714 - acc: 0.9665 - val_loss: 575689.3215 - val_acc: 0.9166\n",
      "Epoch 786/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19308.1116 - acc: 0.9657 - val_loss: 579405.3740 - val_acc: 0.9128\n",
      "Epoch 787/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19158.4724 - acc: 0.9644 - val_loss: 560319.7042 - val_acc: 0.9117\n",
      "Epoch 788/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19682.4102 - acc: 0.9649 - val_loss: 574619.8446 - val_acc: 0.9135\n",
      "Epoch 789/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19445.2143 - acc: 0.9654 - val_loss: 583180.5900 - val_acc: 0.8980\n",
      "Epoch 790/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19100.5627 - acc: 0.9653 - val_loss: 571318.8221 - val_acc: 0.9127\n",
      "Epoch 791/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19115.7274 - acc: 0.9653 - val_loss: 610682.8180 - val_acc: 0.9101\n",
      "Epoch 792/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19290.6055 - acc: 0.9656 - val_loss: 560101.4219 - val_acc: 0.9124\n",
      "Epoch 793/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19025.6549 - acc: 0.9651 - val_loss: 565722.1369 - val_acc: 0.9116\n",
      "Epoch 794/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19486.8348 - acc: 0.9654 - val_loss: 563993.7061 - val_acc: 0.9130\n",
      "Epoch 795/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18882.9142 - acc: 0.9673 - val_loss: 573677.1322 - val_acc: 0.9047\n",
      "Epoch 796/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19067.3386 - acc: 0.9654 - val_loss: 567772.9395 - val_acc: 0.9155\n",
      "Epoch 797/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18945.8413 - acc: 0.9659 - val_loss: 545383.6104 - val_acc: 0.9133\n",
      "Epoch 798/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19246.8279 - acc: 0.9652 - val_loss: 551570.2403 - val_acc: 0.9122\n",
      "Epoch 799/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19458.3373 - acc: 0.9660 - val_loss: 581380.1508 - val_acc: 0.9145\n",
      "Epoch 800/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19206.8696 - acc: 0.9666 - val_loss: 594217.2464 - val_acc: 0.9154\n",
      "Epoch 801/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19497.3001 - acc: 0.9656 - val_loss: 534827.2946 - val_acc: 0.9094\n",
      "Epoch 802/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 19036.6960 - acc: 0.9654 - val_loss: 564240.3048 - val_acc: 0.9014\n",
      "Epoch 803/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19387.3433 - acc: 0.9658 - val_loss: 580914.0411 - val_acc: 0.9157\n",
      "Epoch 804/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18980.2109 - acc: 0.9665 - val_loss: 569513.5759 - val_acc: 0.9128\n",
      "Epoch 805/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19344.5980 - acc: 0.9651 - val_loss: 570687.4929 - val_acc: 0.9085\n",
      "Epoch 806/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19177.3512 - acc: 0.9661 - val_loss: 588011.7230 - val_acc: 0.9159\n",
      "Epoch 807/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19310.3996 - acc: 0.9656 - val_loss: 575640.9083 - val_acc: 0.9131\n",
      "Epoch 808/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19012.3245 - acc: 0.9662 - val_loss: 565032.6813 - val_acc: 0.9116\n",
      "Epoch 809/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19194.2977 - acc: 0.9654 - val_loss: 562541.2914 - val_acc: 0.9096\n",
      "Epoch 810/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18905.9827 - acc: 0.9654 - val_loss: 592097.8311 - val_acc: 0.9097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19476.1257 - acc: 0.9659 - val_loss: 581673.9639 - val_acc: 0.9090\n",
      "Epoch 812/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19021.0171 - acc: 0.9656 - val_loss: 557736.3045 - val_acc: 0.9126\n",
      "Epoch 813/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19004.1386 - acc: 0.9659 - val_loss: 560698.7720 - val_acc: 0.9033\n",
      "Epoch 814/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18594.0720 - acc: 0.9665 - val_loss: 610176.5815 - val_acc: 0.9139\n",
      "Epoch 815/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19058.3493 - acc: 0.9666 - val_loss: 596637.0782 - val_acc: 0.9098\n",
      "Epoch 816/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19167.8279 - acc: 0.9660 - val_loss: 564247.5683 - val_acc: 0.9131\n",
      "Epoch 817/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19035.5753 - acc: 0.9666 - val_loss: 612101.1968 - val_acc: 0.9082\n",
      "Epoch 818/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19029.2759 - acc: 0.9659 - val_loss: 588988.4574 - val_acc: 0.9142\n",
      "Epoch 819/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19013.5766 - acc: 0.9657 - val_loss: 572046.5504 - val_acc: 0.9102\n",
      "Epoch 820/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19074.1079 - acc: 0.9655 - val_loss: 621060.8583 - val_acc: 0.9149\n",
      "Epoch 821/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19007.3596 - acc: 0.9654 - val_loss: 579526.3072 - val_acc: 0.9124\n",
      "Epoch 822/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19032.5785 - acc: 0.9652 - val_loss: 588412.2621 - val_acc: 0.9129\n",
      "Epoch 823/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18726.3317 - acc: 0.9661 - val_loss: 587407.9323 - val_acc: 0.9076\n",
      "Epoch 824/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19359.6486 - acc: 0.9664 - val_loss: 601747.8285 - val_acc: 0.9115\n",
      "Epoch 825/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18625.6218 - acc: 0.9666 - val_loss: 585755.8913 - val_acc: 0.9030\n",
      "Epoch 826/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18959.6698 - acc: 0.9656 - val_loss: 587156.2943 - val_acc: 0.9070\n",
      "Epoch 827/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19068.2711 - acc: 0.9663 - val_loss: 621009.5856 - val_acc: 0.9169\n",
      "Epoch 828/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18925.1545 - acc: 0.9660 - val_loss: 596641.8979 - val_acc: 0.9151\n",
      "Epoch 829/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18842.0734 - acc: 0.9660 - val_loss: 630816.5173 - val_acc: 0.9081\n",
      "Epoch 830/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18861.5151 - acc: 0.9657 - val_loss: 590346.2730 - val_acc: 0.9131\n",
      "Epoch 831/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18751.3720 - acc: 0.9657 - val_loss: 574334.2352 - val_acc: 0.9077\n",
      "Epoch 832/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18822.4249 - acc: 0.9658 - val_loss: 604587.8912 - val_acc: 0.9131\n",
      "Epoch 833/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18918.3819 - acc: 0.9669 - val_loss: 584604.0198 - val_acc: 0.9116\n",
      "Epoch 834/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19219.7646 - acc: 0.9656 - val_loss: 588821.0690 - val_acc: 0.9079\n",
      "Epoch 835/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18868.8520 - acc: 0.9660 - val_loss: 617665.3515 - val_acc: 0.9093\n",
      "Epoch 836/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19085.8762 - acc: 0.9657 - val_loss: 607926.8673 - val_acc: 0.9116\n",
      "Epoch 837/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19044.3971 - acc: 0.9669 - val_loss: 581390.0934 - val_acc: 0.9054\n",
      "Epoch 838/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18861.1385 - acc: 0.9661 - val_loss: 606941.3297 - val_acc: 0.9110\n",
      "Epoch 839/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19041.7073 - acc: 0.9648 - val_loss: 567108.2297 - val_acc: 0.9136\n",
      "Epoch 840/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18758.5031 - acc: 0.9652 - val_loss: 602847.8535 - val_acc: 0.9116\n",
      "Epoch 841/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18952.3625 - acc: 0.9661 - val_loss: 542244.3528 - val_acc: 0.9123\n",
      "Epoch 842/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18632.1324 - acc: 0.9664 - val_loss: 588945.9968 - val_acc: 0.9077\n",
      "Epoch 843/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19047.4572 - acc: 0.9655 - val_loss: 591523.7692 - val_acc: 0.9072\n",
      "Epoch 844/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18646.3627 - acc: 0.9668 - val_loss: 610336.4090 - val_acc: 0.9109\n",
      "Epoch 845/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18966.9058 - acc: 0.9655 - val_loss: 604251.8970 - val_acc: 0.9160\n",
      "Epoch 846/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18945.1322 - acc: 0.9658 - val_loss: 578750.1205 - val_acc: 0.9120\n",
      "Epoch 847/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18953.2062 - acc: 0.9657 - val_loss: 578445.1550 - val_acc: 0.9120\n",
      "Epoch 848/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18494.1335 - acc: 0.9668 - val_loss: 588942.6894 - val_acc: 0.9133\n",
      "Epoch 849/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18896.8333 - acc: 0.9659 - val_loss: 580797.9417 - val_acc: 0.9177\n",
      "Epoch 850/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18941.8916 - acc: 0.9661 - val_loss: 597561.3441 - val_acc: 0.9116\n",
      "Epoch 851/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18620.9399 - acc: 0.9668 - val_loss: 601355.4240 - val_acc: 0.9131\n",
      "Epoch 852/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18765.8636 - acc: 0.9663 - val_loss: 598914.7917 - val_acc: 0.9134\n",
      "Epoch 853/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19201.3086 - acc: 0.9648 - val_loss: 617498.6692 - val_acc: 0.9070\n",
      "Epoch 854/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18362.5754 - acc: 0.9663 - val_loss: 580339.4017 - val_acc: 0.9084\n",
      "Epoch 855/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18847.9171 - acc: 0.9672 - val_loss: 609121.0400 - val_acc: 0.9082\n",
      "Epoch 856/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18714.8489 - acc: 0.9656 - val_loss: 576902.5176 - val_acc: 0.9102\n",
      "Epoch 857/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18723.9495 - acc: 0.9667 - val_loss: 576167.7241 - val_acc: 0.9126\n",
      "Epoch 858/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18744.2407 - acc: 0.9648 - val_loss: 581966.0476 - val_acc: 0.9123\n",
      "Epoch 859/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18744.4959 - acc: 0.9658 - val_loss: 586966.9428 - val_acc: 0.9059\n",
      "Epoch 860/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18786.7237 - acc: 0.9655 - val_loss: 601705.1270 - val_acc: 0.9110\n",
      "Epoch 861/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 19174.7680 - acc: 0.9655 - val_loss: 569231.5163 - val_acc: 0.9139\n",
      "Epoch 862/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18877.5932 - acc: 0.9666 - val_loss: 589409.0362 - val_acc: 0.9165\n",
      "Epoch 863/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18275.5934 - acc: 0.9664 - val_loss: 578850.7190 - val_acc: 0.9062\n",
      "Epoch 864/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18630.8639 - acc: 0.9664 - val_loss: 578228.2827 - val_acc: 0.9134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 865/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18717.4715 - acc: 0.9655 - val_loss: 572024.1044 - val_acc: 0.9100\n",
      "Epoch 866/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18614.2495 - acc: 0.9661 - val_loss: 609660.5732 - val_acc: 0.9086\n",
      "Epoch 867/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18715.8012 - acc: 0.9661 - val_loss: 583193.4676 - val_acc: 0.9084\n",
      "Epoch 868/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18500.4357 - acc: 0.9661 - val_loss: 585737.3378 - val_acc: 0.9085\n",
      "Epoch 869/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18387.4223 - acc: 0.9672 - val_loss: 587011.2630 - val_acc: 0.9078\n",
      "Epoch 870/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18528.9935 - acc: 0.9669 - val_loss: 600359.3908 - val_acc: 0.9054\n",
      "Epoch 871/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18989.3621 - acc: 0.9658 - val_loss: 584193.2301 - val_acc: 0.9132\n",
      "Epoch 872/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18576.1323 - acc: 0.9663 - val_loss: 586816.8765 - val_acc: 0.9109\n",
      "Epoch 873/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18297.9060 - acc: 0.9668 - val_loss: 589658.3514 - val_acc: 0.9125\n",
      "Epoch 874/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18250.8805 - acc: 0.9667 - val_loss: 624206.1226 - val_acc: 0.9151\n",
      "Epoch 875/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18709.1299 - acc: 0.9652 - val_loss: 578191.1277 - val_acc: 0.9116\n",
      "Epoch 876/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18866.0028 - acc: 0.9654 - val_loss: 586703.8238 - val_acc: 0.9111\n",
      "Epoch 877/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18355.4697 - acc: 0.9654 - val_loss: 575186.5503 - val_acc: 0.9075\n",
      "Epoch 878/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18509.6844 - acc: 0.9674 - val_loss: 585724.7625 - val_acc: 0.9113\n",
      "Epoch 879/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18700.1563 - acc: 0.9655 - val_loss: 594024.6507 - val_acc: 0.9088\n",
      "Epoch 880/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18849.4279 - acc: 0.9660 - val_loss: 627523.1458 - val_acc: 0.9096\n",
      "Epoch 881/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18589.4136 - acc: 0.9666 - val_loss: 588064.2270 - val_acc: 0.9107\n",
      "Epoch 882/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18638.1151 - acc: 0.9665 - val_loss: 610126.3255 - val_acc: 0.8979\n",
      "Epoch 883/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18792.6680 - acc: 0.9666 - val_loss: 605682.8691 - val_acc: 0.9070\n",
      "Epoch 884/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18417.9034 - acc: 0.9659 - val_loss: 679238.4285 - val_acc: 0.9091\n",
      "Epoch 885/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18927.5478 - acc: 0.9669 - val_loss: 613987.7461 - val_acc: 0.9141\n",
      "Epoch 886/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18323.2928 - acc: 0.9668 - val_loss: 587855.3296 - val_acc: 0.9124\n",
      "Epoch 887/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18712.1678 - acc: 0.9655 - val_loss: 611339.9930 - val_acc: 0.9107\n",
      "Epoch 888/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18851.1501 - acc: 0.9668 - val_loss: 595364.8056 - val_acc: 0.9130\n",
      "Epoch 889/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18286.6900 - acc: 0.9668 - val_loss: 593576.2870 - val_acc: 0.9084\n",
      "Epoch 890/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18669.8983 - acc: 0.9662 - val_loss: 601242.5609 - val_acc: 0.9084\n",
      "Epoch 891/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18568.8570 - acc: 0.9657 - val_loss: 628549.6493 - val_acc: 0.9104\n",
      "Epoch 892/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18561.2499 - acc: 0.9666 - val_loss: 628313.7960 - val_acc: 0.9096\n",
      "Epoch 893/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18599.6443 - acc: 0.9665 - val_loss: 605131.9502 - val_acc: 0.9034\n",
      "Epoch 894/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18247.6709 - acc: 0.9662 - val_loss: 607459.8584 - val_acc: 0.9090\n",
      "Epoch 895/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18526.6822 - acc: 0.9675 - val_loss: 595720.7898 - val_acc: 0.9074\n",
      "Epoch 896/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18374.2732 - acc: 0.9663 - val_loss: 615032.0955 - val_acc: 0.9103\n",
      "Epoch 897/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18151.7105 - acc: 0.9667 - val_loss: 612921.4076 - val_acc: 0.9082\n",
      "Epoch 898/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18676.9330 - acc: 0.9663 - val_loss: 603705.5428 - val_acc: 0.9096\n",
      "Epoch 899/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18863.3466 - acc: 0.9655 - val_loss: 587669.2693 - val_acc: 0.9121\n",
      "Epoch 900/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18168.0967 - acc: 0.9663 - val_loss: 608716.2837 - val_acc: 0.9110\n",
      "Epoch 901/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18031.1889 - acc: 0.9671 - val_loss: 611963.3204 - val_acc: 0.9101\n",
      "Epoch 902/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18569.7497 - acc: 0.9663 - val_loss: 572876.6661 - val_acc: 0.9142\n",
      "Epoch 903/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 18169.1770 - acc: 0.9667 - val_loss: 641686.2365 - val_acc: 0.9122\n",
      "Epoch 904/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18271.1824 - acc: 0.9668 - val_loss: 599272.7655 - val_acc: 0.9085\n",
      "Epoch 905/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18090.0297 - acc: 0.9673 - val_loss: 598004.8264 - val_acc: 0.9061\n",
      "Epoch 906/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18391.3994 - acc: 0.9663 - val_loss: 606236.3128 - val_acc: 0.9114\n",
      "Epoch 907/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18404.5808 - acc: 0.9663 - val_loss: 596574.8216 - val_acc: 0.9137\n",
      "Epoch 908/1000\n",
      "63424/63424 [==============================] - 3s 42us/sample - loss: 18768.1351 - acc: 0.9666 - val_loss: 606394.8964 - val_acc: 0.9177\n",
      "Epoch 909/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18367.1262 - acc: 0.9660 - val_loss: 625504.3146 - val_acc: 0.9143\n",
      "Epoch 910/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18228.4426 - acc: 0.9662 - val_loss: 624726.0521 - val_acc: 0.9143\n",
      "Epoch 911/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18283.8439 - acc: 0.9677 - val_loss: 609061.3059 - val_acc: 0.9133\n",
      "Epoch 912/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18811.1465 - acc: 0.9662 - val_loss: 596307.9805 - val_acc: 0.9165\n",
      "Epoch 913/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18156.1508 - acc: 0.9676 - val_loss: 600822.4288 - val_acc: 0.9043\n",
      "Epoch 914/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18940.5960 - acc: 0.9666 - val_loss: 621263.9916 - val_acc: 0.9122\n",
      "Epoch 915/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18625.9444 - acc: 0.9655 - val_loss: 615642.8643 - val_acc: 0.9104\n",
      "Epoch 916/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18273.0926 - acc: 0.9668 - val_loss: 588845.8974 - val_acc: 0.9136\n",
      "Epoch 917/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18098.4469 - acc: 0.9652 - val_loss: 627112.2115 - val_acc: 0.9101\n",
      "Epoch 918/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18067.7362 - acc: 0.9658 - val_loss: 598307.4330 - val_acc: 0.9139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 919/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18337.8959 - acc: 0.9672 - val_loss: 603100.0977 - val_acc: 0.9055\n",
      "Epoch 920/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18538.1176 - acc: 0.9672 - val_loss: 649818.3772 - val_acc: 0.9121\n",
      "Epoch 921/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18355.9514 - acc: 0.9670 - val_loss: 613989.4727 - val_acc: 0.9070\n",
      "Epoch 922/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18225.9467 - acc: 0.9662 - val_loss: 601955.3102 - val_acc: 0.9101\n",
      "Epoch 923/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18049.0997 - acc: 0.9665 - val_loss: 607691.4505 - val_acc: 0.8978\n",
      "Epoch 924/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18402.4630 - acc: 0.9680 - val_loss: 620548.8654 - val_acc: 0.9142\n",
      "Epoch 925/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17954.2473 - acc: 0.9663 - val_loss: 619934.8051 - val_acc: 0.9130\n",
      "Epoch 926/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18255.3658 - acc: 0.9670 - val_loss: 597818.0695 - val_acc: 0.9125\n",
      "Epoch 927/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18460.0262 - acc: 0.9668 - val_loss: 597394.9172 - val_acc: 0.9159\n",
      "Epoch 928/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18249.6246 - acc: 0.9661 - val_loss: 622168.1518 - val_acc: 0.9072\n",
      "Epoch 929/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18344.4398 - acc: 0.9667 - val_loss: 619507.5531 - val_acc: 0.9128\n",
      "Epoch 930/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 17876.5645 - acc: 0.9674 - val_loss: 581238.4486 - val_acc: 0.9103\n",
      "Epoch 931/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18279.3328 - acc: 0.9670 - val_loss: 602353.5717 - val_acc: 0.9102\n",
      "Epoch 932/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18391.0860 - acc: 0.9670 - val_loss: 641955.3900 - val_acc: 0.9136\n",
      "Epoch 933/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18143.8486 - acc: 0.9671 - val_loss: 604302.0031 - val_acc: 0.9117\n",
      "Epoch 934/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18046.3607 - acc: 0.9678 - val_loss: 617543.3468 - val_acc: 0.9109\n",
      "Epoch 935/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18193.4964 - acc: 0.9670 - val_loss: 611052.5620 - val_acc: 0.9107\n",
      "Epoch 936/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18400.1965 - acc: 0.9659 - val_loss: 591683.9508 - val_acc: 0.9147\n",
      "Epoch 937/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18316.8141 - acc: 0.9671 - val_loss: 630610.2290 - val_acc: 0.9123\n",
      "Epoch 938/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18323.9934 - acc: 0.9660 - val_loss: 616199.7006 - val_acc: 0.9108\n",
      "Epoch 939/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18319.3218 - acc: 0.9657 - val_loss: 605371.5907 - val_acc: 0.9128\n",
      "Epoch 940/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17997.1370 - acc: 0.9675 - val_loss: 593137.3466 - val_acc: 0.9138\n",
      "Epoch 941/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17925.3404 - acc: 0.9678 - val_loss: 607612.5110 - val_acc: 0.9099\n",
      "Epoch 942/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18065.9145 - acc: 0.9666 - val_loss: 604505.7462 - val_acc: 0.9118\n",
      "Epoch 943/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18406.9913 - acc: 0.9666 - val_loss: 628885.7152 - val_acc: 0.8961\n",
      "Epoch 944/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18038.8407 - acc: 0.9670 - val_loss: 670322.9042 - val_acc: 0.9099\n",
      "Epoch 945/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18035.6512 - acc: 0.9666 - val_loss: 626463.4979 - val_acc: 0.9146\n",
      "Epoch 946/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18299.6494 - acc: 0.9664 - val_loss: 635796.8671 - val_acc: 0.9116\n",
      "Epoch 947/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18136.4159 - acc: 0.9664 - val_loss: 603446.3359 - val_acc: 0.9090\n",
      "Epoch 948/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18054.0155 - acc: 0.9658 - val_loss: 610244.9851 - val_acc: 0.9120\n",
      "Epoch 949/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18233.4498 - acc: 0.9672 - val_loss: 611076.6338 - val_acc: 0.9122\n",
      "Epoch 950/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17979.4600 - acc: 0.9670 - val_loss: 633877.6438 - val_acc: 0.9158\n",
      "Epoch 951/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18219.7592 - acc: 0.9665 - val_loss: 646676.0654 - val_acc: 0.9019\n",
      "Epoch 952/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 17851.3465 - acc: 0.9666 - val_loss: 623478.4236 - val_acc: 0.9098\n",
      "Epoch 953/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17876.6280 - acc: 0.9661 - val_loss: 606789.0639 - val_acc: 0.9081\n",
      "Epoch 954/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18000.5861 - acc: 0.9669 - val_loss: 624507.4003 - val_acc: 0.9107\n",
      "Epoch 955/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18308.8168 - acc: 0.9670 - val_loss: 630500.6975 - val_acc: 0.9144\n",
      "Epoch 956/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18077.1835 - acc: 0.9667 - val_loss: 630674.3908 - val_acc: 0.9153\n",
      "Epoch 957/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18190.3642 - acc: 0.9668 - val_loss: 616695.4570 - val_acc: 0.9061\n",
      "Epoch 958/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18092.6597 - acc: 0.9674 - val_loss: 605278.0981 - val_acc: 0.9147\n",
      "Epoch 959/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 17723.5110 - acc: 0.9667 - val_loss: 617011.5498 - val_acc: 0.9101\n",
      "Epoch 960/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18238.5529 - acc: 0.9656 - val_loss: 634161.9110 - val_acc: 0.9046\n",
      "Epoch 961/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18028.0166 - acc: 0.9672 - val_loss: 608976.7871 - val_acc: 0.9077\n",
      "Epoch 962/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17961.6764 - acc: 0.9676 - val_loss: 604643.8144 - val_acc: 0.9172\n",
      "Epoch 963/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18015.3130 - acc: 0.9668 - val_loss: 638055.1561 - val_acc: 0.9093\n",
      "Epoch 964/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18218.0648 - acc: 0.9664 - val_loss: 625088.3044 - val_acc: 0.9042\n",
      "Epoch 965/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17874.8147 - acc: 0.9671 - val_loss: 641358.4074 - val_acc: 0.9060\n",
      "Epoch 966/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17915.0316 - acc: 0.9669 - val_loss: 608915.4081 - val_acc: 0.9072\n",
      "Epoch 967/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 17842.8536 - acc: 0.9665 - val_loss: 641931.0177 - val_acc: 0.9126\n",
      "Epoch 968/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17813.7097 - acc: 0.9679 - val_loss: 625861.9576 - val_acc: 0.9151\n",
      "Epoch 969/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18199.4884 - acc: 0.9669 - val_loss: 601061.6403 - val_acc: 0.9102\n",
      "Epoch 970/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17933.6062 - acc: 0.9673 - val_loss: 613259.7007 - val_acc: 0.9154\n",
      "Epoch 971/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18097.5638 - acc: 0.9669 - val_loss: 633728.0131 - val_acc: 0.9087\n",
      "Epoch 972/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 17966.6708 - acc: 0.9680 - val_loss: 617024.0340 - val_acc: 0.9066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18036.0994 - acc: 0.9659 - val_loss: 625878.0793 - val_acc: 0.9097\n",
      "Epoch 974/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 17859.3625 - acc: 0.9672 - val_loss: 621376.4089 - val_acc: 0.9054\n",
      "Epoch 975/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17959.7223 - acc: 0.9667 - val_loss: 637301.7030 - val_acc: 0.9122\n",
      "Epoch 976/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18223.8382 - acc: 0.9667 - val_loss: 580009.8946 - val_acc: 0.9102\n",
      "Epoch 977/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17801.1872 - acc: 0.9672 - val_loss: 650783.7068 - val_acc: 0.9101\n",
      "Epoch 978/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18045.3408 - acc: 0.9675 - val_loss: 663774.5124 - val_acc: 0.9119\n",
      "Epoch 979/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18042.5132 - acc: 0.9677 - val_loss: 639667.1633 - val_acc: 0.9058\n",
      "Epoch 980/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18214.2346 - acc: 0.9663 - val_loss: 651265.2843 - val_acc: 0.9133\n",
      "Epoch 981/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17670.7364 - acc: 0.9672 - val_loss: 627257.7451 - val_acc: 0.9074\n",
      "Epoch 982/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 18086.4664 - acc: 0.9673 - val_loss: 601677.5330 - val_acc: 0.9075\n",
      "Epoch 983/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18171.5203 - acc: 0.9668 - val_loss: 629946.8378 - val_acc: 0.9127\n",
      "Epoch 984/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 17802.6112 - acc: 0.9675 - val_loss: 630518.7285 - val_acc: 0.9124\n",
      "Epoch 985/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17840.3127 - acc: 0.9669 - val_loss: 604836.4736 - val_acc: 0.9144\n",
      "Epoch 986/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18281.7780 - acc: 0.9673 - val_loss: 593074.2725 - val_acc: 0.9141\n",
      "Epoch 987/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17749.0210 - acc: 0.9679 - val_loss: 650620.3451 - val_acc: 0.9123\n",
      "Epoch 988/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 17452.7239 - acc: 0.9675 - val_loss: 641115.3646 - val_acc: 0.9090\n",
      "Epoch 989/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17917.7711 - acc: 0.9674 - val_loss: 617981.6963 - val_acc: 0.9078\n",
      "Epoch 990/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17802.6708 - acc: 0.9663 - val_loss: 628093.0976 - val_acc: 0.9060\n",
      "Epoch 991/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17631.7831 - acc: 0.9675 - val_loss: 612583.2920 - val_acc: 0.9081\n",
      "Epoch 992/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17828.9066 - acc: 0.9669 - val_loss: 632296.8341 - val_acc: 0.8996\n",
      "Epoch 993/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18003.8066 - acc: 0.9670 - val_loss: 622961.9185 - val_acc: 0.9034\n",
      "Epoch 994/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17911.1423 - acc: 0.9672 - val_loss: 666936.0223 - val_acc: 0.9119\n",
      "Epoch 995/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17766.4051 - acc: 0.9672 - val_loss: 606693.6458 - val_acc: 0.9074\n",
      "Epoch 996/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17816.9400 - acc: 0.9676 - val_loss: 632492.5989 - val_acc: 0.9102\n",
      "Epoch 997/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 18058.5900 - acc: 0.9662 - val_loss: 605664.2408 - val_acc: 0.9118\n",
      "Epoch 998/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17578.6480 - acc: 0.9675 - val_loss: 619541.3558 - val_acc: 0.9081\n",
      "Epoch 999/1000\n",
      "63424/63424 [==============================] - 3s 41us/sample - loss: 17831.5089 - acc: 0.9674 - val_loss: 630379.2004 - val_acc: 0.9078\n",
      "Epoch 1000/1000\n",
      "63424/63424 [==============================] - 3s 40us/sample - loss: 17755.8427 - acc: 0.9673 - val_loss: 642208.6009 - val_acc: 0.9131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efb147edef0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(P_train, q_train, validation_data = (P_test, q_test), epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:56:29.688706Z",
     "start_time": "2020-03-06T20:56:14.454318Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,100))\n",
    "\n",
    "plt.plot(model.predict(X)[:,0][:10000])\n",
    "plt.plot(q[:,0][:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:17:16.610271Z",
     "start_time": "2020-03-06T20:17:06.157980Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,100))\n",
    "\n",
    "plt.plot(model.predict(X)[:,1][:10000])\n",
    "plt.plot(q[:,1][:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:17:35.008271Z",
     "start_time": "2020-03-06T20:17:16.610271Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,100))\n",
    "\n",
    "plt.plot(model.predict(X)[:,1][:1000])\n",
    "plt.plot(model.predict(X)[:,0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:17:39.500511Z",
     "start_time": "2020-03-06T20:17:35.008271Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,100))\n",
    "\n",
    "plt.plot(q[:,1][:1000])\n",
    "plt.plot(q[:,0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T21:02:05.360675Z",
     "start_time": "2020-03-06T21:01:51.648016Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "ploty = pd.DataFrame({'x_pred':model.predict(X)[:,0], 'y_pred':model.predict(X)[:,1], 'x_diff':df['x_diff'], \n",
    "                    'y_diff':df['y_diff']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T21:02:05.375659Z",
     "start_time": "2020-03-06T21:02:05.362650Z"
    }
   },
   "outputs": [],
   "source": [
    "ploty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T21:04:20.640681Z",
     "start_time": "2020-03-06T21:04:20.622681Z"
    }
   },
   "outputs": [],
   "source": [
    "ploty['x_pred_dif'] = ploty['x_pred'].diff()\n",
    "ploty['y_pred_dif'] = ploty['y_pred'].diff()\n",
    "ploty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T21:07:33.333318Z",
     "start_time": "2020-03-06T21:07:33.300292Z"
    }
   },
   "outputs": [],
   "source": [
    "ploty.dropna(inplace=True)\n",
    "ploty.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T21:08:02.191908Z",
     "start_time": "2020-03-06T21:07:57.043704Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,100))\n",
    "plt.plot(ploty['x_pred_dif'][:1000])\n",
    "plt.plot(ploty['x_diff'][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T21:08:11.243418Z",
     "start_time": "2020-03-06T21:08:06.637343Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,100))\n",
    "plt.plot(ploty['y_pred_dif'][:1000])\n",
    "plt.plot(ploty['y_diff'][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
